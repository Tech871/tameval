[meta]
task = "create"
scenario = "extend_test_file"

[lang_info]
lang = "Python"
python_version = "3.13"
python_cfg_file = "pyproject.toml"

[repo_info]
repository = "damianvtran/local-operator"
sha = "2fd6ef34ce6fad7889fba35bbf5a1a49ff447720"

[run_info]
docker_image = "python:3.13"
volumes_to_mount = [ "{proj_path}:/app", "{host}/.m2:/.m2", "{host}/.cache/pip:/.pip_cache", "{host}/.cache/go-build:/.go_cache", "{proj_path}/_HOME_/go:/go",]
docker_wrap = "sudo docker run --rm -w /app -e PATH=_HOME_/.local/bin:$PATH -e PYTHONUSERBASE=_HOME_/.local/ -v {proj_path}:/app -v {host}/.m2:/.m2 -v {host}/.cache/pip:/.pip_cache -v {host}/.cache/go-build:/.go_cache -v {proj_path}/_HOME_/go:/go {img} sh -c '{cmd}'"
env = [ "PATH=_HOME_/.local/bin:$PATH", "PYTHONUSERBASE=_HOME_/.local/",]
prebuild_command = "pip install -r requirements.txt && (pip install .[all,test] && pip install git+https://github.com/Klema17/mutpy.git && pip install coverage pytest pytest_cov covdefaults Cython mock ddt pytest_mock testfixtures)"
test_run_command = "coverage run --include=local_operator/admin.py -m pytest -q --junit-xml=test_output.xml tests/unit/test_admin.py && coverage xml -o coverage.xml --fail-under=0"
mutation_run_command = "mut.py --target local_operator.admin --unit-test tests.unit.test_admin --runner pytest --report mutation_report.yaml"
mutation_run_command_fallback = "mut.py --target local_operator/admin.py --unit-test tests/unit/test_admin.py --runner pytest --report mutation_report.yaml"
coverage_report_path = "coverage.xml"
coverage_report_type = "cobertura"
mutation_report_path = "mutation_report.yaml"
mutation_report_type = "mutpy"

[coverage]
coverage = 75.0
original_coverage = 75.0
mutation_kill_rate = 61.0
original_mutation_kill_rate = 61.0
covered_lines = [ 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 43, 65, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 94, 115, 127, 129, 132, 159, 172, 173, 176, 177, 178, 180, 181, 182, 183, 186, 187, 188, 190, 196, 200, 202, 205, 224, 240, 241, 242, 244, 247, 261, 274, 296, 299, 314, 327, 328, 330, 332, 335, 349, 358, 360, 363, 379, 391, 392, 393, 394, 396, 399, 420, 437, 439, 442, 443, 455, 458, 471, 483, 485, 488, 506, 523, 524, 528, 531, 547, 572, 575, 591, 616, 619, 632, 659, 662, 686, 693, 697, 701, 705, 709, 713, 717, 721, 725, 729,]
missed_lines = [ 329, 450, 451, 452, 453, 525, 526, 556, 557, 558, 559, 561, 562, 563, 564, 565, 567, 569, 570, 600, 601, 602, 603, 605, 606, 607, 608, 609, 611, 613, 614, 645, 646, 654, 656, 657,]

[input_info]
test_file_path = "tests/unit/test_admin.py"
focal_file_path = "local_operator/admin.py"
test_file_url = "https://github.com/damianvtran/local-operator/blob/2fd6ef34ce6fad7889fba35bbf5a1a49ff447720/tests/unit/test_admin.py"
focal_file_url = "https://github.com/damianvtran/local-operator/blob/2fd6ef34ce6fad7889fba35bbf5a1a49ff447720/local_operator/admin.py"
first_commit_date = "2025-02-12"
last_commit_date = "2025-05-18"
test_file_content = "\"\"\"\nUnit tests for admin tools.\n\nThese tests cover functionalities such as agent creation from conversation,\ntraining data saving, agent info lookup, and configuration handling.\nMock implementations are used throughout in order to avoid side effects and to\nisolate behaviors.\n\"\"\"\n\nimport json\nfrom pathlib import Path\nfrom typing import Any\nfrom unittest.mock import AsyncMock, MagicMock\n\nimport pytest\n\nfrom local_operator.admin import (\n    AgentRegistry,\n    LocalCodeExecutor,\n    add_admin_tools,\n    create_agent_from_conversation_tool,\n    create_agent_tool,\n    delete_agent_tool,\n    edit_agent_tool,\n    get_agent_info_tool,\n    get_config_tool,\n    list_agent_info_tool,\n    save_agent_training_tool,\n    save_conversation_raw_json_tool,\n    update_config_tool,\n)\nfrom local_operator.agents import AgentEditFields\nfrom local_operator.config import Config, ConfigManager\nfrom local_operator.tools.general import ToolRegistry\nfrom local_operator.types import (\n    CodeExecutionResult,\n    ConversationRecord,\n    ConversationRole,\n    ProcessResponseStatus,\n)\n\n\n@pytest.fixture\ndef temp_agents_dir(tmp_path: Path) -> Path:\n    dir_path = tmp_path / \"agents_test\"\n    dir_path.mkdir()\n    return dir_path\n\n\n@pytest.fixture\ndef temp_config_dir(tmp_path: Path) -> Path:\n    dir_path = tmp_path / \"config_test\"\n    dir_path.mkdir()\n    return dir_path\n\n\n@pytest.fixture\ndef mock_model():\n    model = AsyncMock()\n    model.ainvoke = AsyncMock()\n    return model\n\n\n@pytest.fixture\ndef executor(mock_model):\n    agent = MagicMock()\n    agent.id = \"test_agent\"\n    agent.name = \"Test Agent\"\n    agent.version = \"1.0.0\"\n    agent.security_prompt = \"\"\n    return LocalCodeExecutor(mock_model, agent=agent)\n\n\n@pytest.fixture\ndef agent_registry(temp_agents_dir: Path):\n    return AgentRegistry(temp_agents_dir)\n\n\n@pytest.fixture\ndef tool_registry():\n    registry = ToolRegistry()\n    return registry\n\n\n@pytest.fixture\ndef config_manager(temp_config_dir: Path) -> ConfigManager:\n    manager = ConfigManager(config_dir=temp_config_dir)\n    manager.update_config(\n        {\n            \"conversation_length\": 5,\n            \"detail_length\": 3,\n            \"hosting\": \"test_host\",\n            \"model_name\": \"test_model\",\n        }\n    )\n    return manager\n\n\ndef test_create_agent_from_conversation_no_user_messages(\n    temp_agents_dir: Path, executor: LocalCodeExecutor, agent_registry: AgentRegistry\n) -> None:\n    \"\"\"\n    Test creating an agent from a conversation that contains no user messages.\n    The expected saved conversation history should be empty.\n    \"\"\"\n    executor.agent_state.conversation = [\n        ConversationRecord(role=ConversationRole.SYSTEM, content=\"Initial prompt\")\n    ]\n    create_tool = create_agent_from_conversation_tool(executor, agent_registry)\n    agent_name = \"TestAgent\"\n    new_agent = create_tool(agent_name)\n    saved_history = agent_registry.load_agent_state(new_agent.id)\n    assert (\n        saved_history.conversation == []\n    ), f\"Expected empty conversation history, got {saved_history}\"\n    assert (\n        saved_history.execution_history == []\n    ), f\"Expected empty execution history, got {saved_history}\"\n\n\ndef test_create_agent_from_conversation_with_user_messages(\n    executor: LocalCodeExecutor, agent_registry: AgentRegistry\n) -> None:\n    \"\"\"\n    Test creating an agent from a conversation that contains multiple user messages.\n    Verifies that the conversation history is truncated based on the cutoff index before\n    the last user message.\n    \"\"\"\n    conversation_history = [\n        ConversationRecord(role=ConversationRole.SYSTEM, content=\"Initial prompt\"),\n        ConversationRecord(role=ConversationRole.USER, content=\"First user message\"),\n        ConversationRecord(role=ConversationRole.USER, content=\"Second user message\"),\n        ConversationRecord(role=ConversationRole.ASSISTANT, content=\"Response\"),\n        ConversationRecord(role=ConversationRole.USER, content=\"Third user message\"),\n        ConversationRecord(role=ConversationRole.SYSTEM, content=\"System message\"),\n    ]\n    executor.agent_state.execution_history = [\n        CodeExecutionResult(\n            id=\"test_code_execution_id\",\n            stdout=\"\",\n            stderr=\"\",\n            logging=\"\",\n            message=\"This is a test code execution result\",\n            code=\"print('Hello, world!')\",\n            formatted_print=\"Hello, world!\",\n            role=ConversationRole.ASSISTANT,\n            status=ProcessResponseStatus.SUCCESS,\n            files=[],\n        )\n    ]\n    executor.agent_state.conversation = conversation_history\n    create_tool = create_agent_from_conversation_tool(executor, agent_registry)\n    agent_name = \"TestAgent2\"\n    new_agent = create_tool(agent_name)\n    saved_history = agent_registry.load_agent_state(new_agent.id)\n    expected_history = conversation_history[:4]\n    expected_execution_history = [\n        CodeExecutionResult(\n            id=\"test_code_execution_id\",\n            stdout=\"\",\n            stderr=\"\",\n            logging=\"\",\n            message=\"This is a test code execution result\",\n            code=\"print('Hello, world!')\",\n            formatted_print=\"Hello, world!\",\n            role=ConversationRole.ASSISTANT,\n            status=ProcessResponseStatus.SUCCESS,\n            files=[],\n        )\n    ]\n\n    assert (\n        saved_history.conversation == expected_history\n    ), f\"Expected conversation history {expected_history}, got {saved_history}\"\n    assert (\n        saved_history.execution_history == expected_execution_history\n    ), f\"Expected execution history {expected_execution_history}, got {saved_history}\"\n\n\ndef test_save_agent_training_no_agent(\n    executor: LocalCodeExecutor, agent_registry: AgentRegistry\n) -> None:\n    \"\"\"\n    Test saving agent training data when no current agent is set.\n    Expect a ValueError to be raised with the appropriate message.\n    \"\"\"\n    conversation_history = [ConversationRecord(role=ConversationRole.USER, content=\"User message\")]\n    executor.agent_state.conversation = conversation_history\n    executor.agent = None\n    save_training_tool = save_agent_training_tool(executor, agent_registry)\n    with pytest.raises(ValueError, match=\"No current agent set\"):\n        save_training_tool()\n\n\ndef test_save_agent_training_with_agent(\n    executor: LocalCodeExecutor, agent_registry: AgentRegistry\n) -> None:\n    \"\"\"\n    Test saving agent training data when a current agent is available.\n    The conversation history should be truncated correctly and the agent remains unchanged.\n    \"\"\"\n    conversation_history = [\n        ConversationRecord(role=ConversationRole.SYSTEM, content=\"System message\"),\n        ConversationRecord(role=ConversationRole.USER, content=\"User message 1\"),\n        ConversationRecord(role=ConversationRole.USER, content=\"User message 2\"),\n        ConversationRecord(role=ConversationRole.ASSISTANT, content=\"Assistant reply\"),\n    ]\n    execution_history = [\n        CodeExecutionResult(\n            id=\"test_code_execution_id\",\n            stdout=\"\",\n            stderr=\"\",\n            logging=\"\",\n            message=\"This is a test code execution result\",\n            code=\"print('Hello, world!')\",\n            formatted_print=\"Hello, world!\",\n            role=ConversationRole.ASSISTANT,\n            status=ProcessResponseStatus.SUCCESS,\n            files=[],\n        ),\n        CodeExecutionResult(\n            id=\"test_code_execution_id2\",\n            stdout=\"\",\n            stderr=\"\",\n            logging=\"\",\n            message=\"This is a second test code execution result\",\n            code=\"print('Lorem ipsum dolor sit amet!')\",\n            formatted_print=\"Lorem ipsum dolor sit amet!\",\n            role=ConversationRole.ASSISTANT,\n            status=ProcessResponseStatus.SUCCESS,\n            files=[],\n        ),\n    ]\n    executor.agent_state.conversation = conversation_history\n    executor.agent_state.execution_history = execution_history\n    agent = agent_registry.create_agent(\n        AgentEditFields(\n            name=\"TrainAgent\",\n            security_prompt=\"\",\n            hosting=\"\",\n            model=\"\",\n            description=\"\",\n            last_message=\"\",\n            tags=[\"test-tag1\", \"test-tag2\"],\n            categories=[\"test-category1\", \"test-category2\"],\n            temperature=0.7,\n            top_p=1.0,\n            top_k=None,\n            max_tokens=2048,\n            stop=None,\n            frequency_penalty=0.0,\n            presence_penalty=0.0,\n            seed=None,\n            current_working_directory=None,\n        )\n    )\n    executor.agent = agent\n    save_training_tool = save_agent_training_tool(executor, agent_registry)\n    updated_agent = save_training_tool()\n    expected_history = conversation_history[:2]\n    expected_execution_history = execution_history\n    stored_history = agent_registry.load_agent_state(agent.id)\n    assert (\n        stored_history.conversation == expected_history\n    ), f\"Expected conversation history {expected_history}, got {stored_history}\"\n    assert (\n        stored_history.execution_history == expected_execution_history\n    ), f\"Expected execution history {expected_execution_history}, got {stored_history}\"\n    assert updated_agent == agent, \"The updated agent does not match the original agent.\"\n\n\ndef test_list_agent_info_without_id(agent_registry: AgentRegistry) -> None:\n    \"\"\"\n    Test listing agent information without specifying an agent ID.\n    All agents stored in the registry should be returned.\n    \"\"\"\n    agent1 = agent_registry.create_agent(\n        AgentEditFields(\n            name=\"Agent1\",\n            security_prompt=\"prompt1\",\n            hosting=\"\",\n            model=\"\",\n            description=\"\",\n            last_message=\"\",\n            tags=[\"test-tag1\", \"test-tag2\"],\n            categories=[\"test-category1\", \"test-category2\"],\n            temperature=0.7,\n            top_p=1.0,\n            top_k=None,\n            max_tokens=2048,\n            stop=None,\n            frequency_penalty=0.0,\n            presence_penalty=0.0,\n            seed=None,\n            current_working_directory=None,\n        )\n    )\n    agent2 = agent_registry.create_agent(\n        AgentEditFields(\n            name=\"Agent2\",\n            security_prompt=\"prompt2\",\n            hosting=\"\",\n            model=\"\",\n            description=\"\",\n            last_message=\"\",\n            tags=[\"test-tag1\", \"test-tag2\"],\n            categories=[\"test-category1\", \"test-category2\"],\n            temperature=0.7,\n            top_p=1.0,\n            top_k=None,\n            max_tokens=2048,\n            stop=None,\n            frequency_penalty=0.0,\n            presence_penalty=0.0,\n            seed=None,\n            current_working_directory=None,\n        )\n    )\n    list_tool = list_agent_info_tool(agent_registry)\n    agents_list = list_tool(None)\n    assert len(agents_list) == 2, f\"Expected 2 agents, got {len(agents_list)}\"\n    agent_ids = {agent1.id, agent2.id}\n    returned_ids = {agent.id for agent in agents_list}\n    assert agent_ids == returned_ids, f\"Expected agent ids {agent_ids}, got {returned_ids}\"\n\n\ndef test_list_agent_info_with_id(agent_registry: AgentRegistry) -> None:\n    \"\"\"\n    Test retrieving agent information for a specific agent ID.\n    Only the desired agent should be returned.\n    \"\"\"\n    agent = agent_registry.create_agent(\n        AgentEditFields(\n            name=\"AgentX\",\n            security_prompt=\"promptX\",\n            hosting=\"\",\n            model=\"\",\n            description=\"\",\n            last_message=\"\",\n            tags=[\"test-tag1\", \"test-tag2\"],\n            categories=[\"test-category1\", \"test-category2\"],\n            temperature=0.7,\n            top_p=1.0,\n            top_k=None,\n            max_tokens=2048,\n            stop=None,\n            frequency_penalty=0.0,\n            presence_penalty=0.0,\n            seed=None,\n            current_working_directory=None,\n        )\n    )\n    list_tool = list_agent_info_tool(agent_registry)\n    agent_list = list_tool(agent.id)\n    assert len(agent_list) == 1, f\"Expected 1 agent, got {len(agent_list)}\"\n    assert agent_list[0].id == agent.id, f\"Expected agent id {agent.id}, got {agent_list[0].id}\"\n\n\ndef test_create_agent_tool(agent_registry: AgentRegistry) -> None:\n    \"\"\"\n    Test the create_agent_tool function to ensure it creates an agent with the proper details.\n    \"\"\"\n    create_tool = create_agent_tool(agent_registry)\n    agent = create_tool(\"NewAgent\", \"secure\")\n    assert agent.name == \"NewAgent\", f\"Expected agent name 'NewAgent', got {agent.name}\"\n    assert (\n        agent.security_prompt == \"secure\"\n    ), f\"Expected security prompt 'secure', got {agent.security_prompt}\"\n    assert agent.id in agent_registry._agents, f\"Agent id {agent.id} not found in registry\"\n\n\ndef test_edit_agent_tool(agent_registry: AgentRegistry) -> None:\n    \"\"\"\n    Test the edit_agent_tool to verify that an agent's name and security prompt update correctly.\n    \"\"\"\n    agent = agent_registry.create_agent(\n        AgentEditFields(\n            name=\"OldName\",\n            security_prompt=\"old\",\n            hosting=\"\",\n            model=\"\",\n            description=\"\",\n            last_message=\"\",\n            tags=[\"test-tag1\", \"test-tag2\"],\n            categories=[\"test-category1\", \"test-category2\"],\n            temperature=0.7,\n            top_p=1.0,\n            top_k=None,\n            max_tokens=2048,\n            stop=None,\n            frequency_penalty=0.0,\n            presence_penalty=0.0,\n            seed=None,\n            current_working_directory=None,\n        )\n    )\n    edit_tool = edit_agent_tool(agent_registry)\n    updated_agent = edit_tool(\n        agent.id,\n        AgentEditFields(\n            name=\"NewName\",\n            security_prompt=\"new\",\n            hosting=\"\",\n            model=\"\",\n            description=\"\",\n            last_message=\"\",\n            tags=[\"test-tag1\", \"test-tag2\"],\n            categories=[\"test-category1\", \"test-category2\"],\n            temperature=0.7,\n            top_p=1.0,\n            top_k=None,\n            max_tokens=2048,\n            stop=None,\n            frequency_penalty=0.0,\n            presence_penalty=0.0,\n            seed=None,\n            current_working_directory=None,\n        ),\n    )\n    assert updated_agent is not None, \"edit_agent_tool returned None\"\n    assert updated_agent.name == \"NewName\", f\"Expected 'NewName', got {updated_agent.name}\"\n    assert (\n        updated_agent.security_prompt == \"new\"\n    ), f\"Expected security prompt 'new', got {updated_agent.security_prompt}\"\n\n\ndef test_delete_agent_tool(agent_registry: AgentRegistry) -> None:\n    \"\"\"\n    Test the delete_agent_tool to confirm an agent is removed from the registry.\n    \"\"\"\n    agent = agent_registry.create_agent(\n        AgentEditFields(\n            name=\"ToDelete\",\n            security_prompt=\"\",\n            hosting=\"\",\n            model=\"\",\n            description=\"\",\n            last_message=\"\",\n            tags=[\"test-tag1\", \"test-tag2\"],\n            categories=[\"test-category1\", \"test-category2\"],\n            temperature=0.7,\n            top_p=1.0,\n            top_k=None,\n            max_tokens=2048,\n            stop=None,\n            frequency_penalty=0.0,\n            presence_penalty=0.0,\n            seed=None,\n            current_working_directory=None,\n        )\n    )\n    delete_tool = delete_agent_tool(agent_registry)\n    delete_tool(agent.id)\n    with pytest.raises(KeyError, match=rf\"Agent with id {agent.id} not found\"):\n        agent_registry.get_agent(agent.id)\n\n\ndef test_get_agent_info_tool_without_id(agent_registry: AgentRegistry) -> None:\n    \"\"\"\n    Test get_agent_info_tool returns all agents when no id is provided.\n    \"\"\"\n    agent_registry.create_agent(\n        AgentEditFields(\n            name=\"Agent1\",\n            security_prompt=\"\",\n            hosting=\"\",\n            model=\"\",\n            description=\"\",\n            last_message=\"\",\n            tags=[\"test-tag1\", \"test-tag2\"],\n            categories=[\"test-category1\", \"test-category2\"],\n            temperature=0.7,\n            top_p=1.0,\n            top_k=None,\n            max_tokens=2048,\n            stop=None,\n            frequency_penalty=0.0,\n            presence_penalty=0.0,\n            seed=None,\n            current_working_directory=None,\n        )\n    )\n    agent_registry.create_agent(\n        AgentEditFields(\n            name=\"Agent2\",\n            security_prompt=\"\",\n            hosting=\"\",\n            model=\"\",\n            description=\"\",\n            last_message=\"\",\n            tags=[\"test-tag1\", \"test-tag2\"],\n            categories=[\"test-category1\", \"test-category2\"],\n            temperature=0.7,\n            top_p=1.0,\n            top_k=None,\n            max_tokens=2048,\n            stop=None,\n            frequency_penalty=0.0,\n            presence_penalty=0.0,\n            seed=None,\n            current_working_directory=None,\n        )\n    )\n    get_tool = get_agent_info_tool(agent_registry)\n    agents = get_tool(None)\n    assert len(agents) == 2, f\"Expected 2 agents, got {len(agents)}\"\n\n\ndef test_get_agent_info_tool_with_id(agent_registry: AgentRegistry) -> None:\n    \"\"\"\n    Test get_agent_info_tool returns information for the specified agent.\n    \"\"\"\n    agent = agent_registry.create_agent(\n        AgentEditFields(\n            name=\"AgentSingle\",\n            security_prompt=\"\",\n            hosting=\"\",\n            model=\"\",\n            description=\"\",\n            last_message=\"\",\n            tags=[\"test-tag1\", \"test-tag2\"],\n            categories=[\"test-category1\", \"test-category2\"],\n            temperature=0.7,\n            top_p=1.0,\n            top_k=None,\n            max_tokens=2048,\n            stop=None,\n            frequency_penalty=0.0,\n            presence_penalty=0.0,\n            seed=None,\n            current_working_directory=None,\n        )\n    )\n    get_tool = get_agent_info_tool(agent_registry)\n    result = get_tool(agent.id)\n    assert len(result) == 1, f\"Expected 1 agent, got {len(result)}\"\n    assert result[0].id == agent.id, f\"Expected agent id {agent.id}, got {result[0].id}\"\n\n\ndef test_save_conversation_tool(tmp_path: Any, executor: LocalCodeExecutor) -> None:\n    \"\"\"\n    Test the save_conversation_tool to verify that the conversation history is written to a file.\n    \"\"\"\n    file_path = tmp_path / \"conversation.json\"\n    conversation_history = [\n        ConversationRecord(role=ConversationRole.USER, content=\"Hello\"),\n        ConversationRecord(role=ConversationRole.ASSISTANT, content=\"Hi there!\"),\n    ]\n    executor.agent_state.conversation = conversation_history\n    save_tool = save_conversation_raw_json_tool(executor)\n    save_tool(str(file_path))\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    assert isinstance(data, list), \"Saved JSON data is not a list\"\n    for msg in data:\n        assert isinstance(msg, dict), f\"Message {msg} is not a dict\"\n        assert \"role\" in msg, f\"Message {msg} missing key 'role'\"\n        assert \"content\" in msg, f\"Message {msg} missing key 'content'\"\n\n\ndef test_get_config_tool(config_manager: ConfigManager) -> None:\n    \"\"\"\n    Test the get_config_tool to verify it returns the correct configuration.\n    \"\"\"\n    get_tool = get_config_tool(config_manager)\n    config = get_tool()\n    assert isinstance(config, Config), \"Configuration is not a Config object\"\n    assert config.get_value(\"conversation_length\") == 5\n    assert config.get_value(\"detail_length\") == 3\n    assert config.get_value(\"hosting\") == \"test_host\"\n    assert config.get_value(\"model_name\") == \"test_model\"\n\n\ndef test_update_config_tool(config_manager: ConfigManager) -> None:\n    \"\"\"\n    Test the update_config_tool to check that configuration updates are applied correctly.\n    \"\"\"\n    update_tool = update_config_tool(config_manager)\n    update_tool({\"new_key\": \"new_value\"})\n    config = config_manager.get_config()\n    assert (\n        config.get_value(\"new_key\") == \"new_value\"\n    ), f\"Expected 'new_value' for 'new_key', got {config.get_value('new_key')}\"\n\n\ndef test_add_admin_tools(\n    tool_registry: ToolRegistry,\n    executor: LocalCodeExecutor,\n    agent_registry: AgentRegistry,\n    config_manager: ConfigManager,\n) -> None:\n    \"\"\"\n    Test add_admin_tools to ensure that all expected admin tools\n    are registered in the tool registry.\n    \"\"\"\n    add_admin_tools(tool_registry, executor, agent_registry, config_manager)\n    expected_tools = {\n        \"create_agent_from_conversation\",\n        \"edit_agent\",\n        \"delete_agent\",\n        \"get_agent_info\",\n        \"save_conversation_raw_json\",\n        \"get_config\",\n        \"update_config\",\n        \"save_agent_training\",\n        \"open_agents_config\",\n        \"open_settings_config\",\n        \"save_conversation_history_to_notebook\",\n    }\n    tools_set = set(tool_registry._tools.keys())\n    # Check that all expected tools are present, but allow for additional builtin tools\n    assert expected_tools.issubset(tools_set), (\n        f\"Missing expected tools. Expected subset {expected_tools}, \"\n        f\"but registry only contains {tools_set}\"\n    )\n"
