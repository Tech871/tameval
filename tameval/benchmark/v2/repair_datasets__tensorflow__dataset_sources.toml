[meta]
task = "repair"
scenario = "repair_missed_asserts"

[lang_info]
lang = "Python"
python_cfg_file = "pyproject.toml"

[repo_info]
repository = "tensorflow/datasets"
sha = "5afdc02a1a6ce1a5ded7e2395c7a3498216936bb"

[run_info]
docker_image = "python:3"
volumes_to_mount = [ "{proj_path}:/app", "{host}/.m2:/.m2", "{host}/.cache/pip:/.pip_cache", "{host}/.cache/go-build:/.go_cache", "{proj_path}/_HOME_/go:/go",]
docker_wrap = "sudo docker run --rm -w /app -e PATH=_HOME_/.local/bin:$PATH -e PYTHONUSERBASE=_HOME_/.local/ -v {proj_path}:/app -v {host}/.m2:/.m2 -v {host}/.cache/pip:/.pip_cache -v {host}/.cache/go-build:/.go_cache -v {proj_path}/_HOME_/go:/go {img} sh -c '{cmd}'"
env = [ "PATH=_HOME_/.local/bin:$PATH", "PYTHONUSERBASE=_HOME_/.local/",]
prebuild_command = "(pip install .[all,test] && pip install git+https://github.com/Klema17/mutpy.git && pip install coverage pytest pytest_cov covdefaults Cython mock ddt pytest_mock testfixtures)"
test_run_command = "coverage run --include=tensorflow_datasets/core/community/dataset_sources.py -m pytest -q --junit-xml=test_output.xml tensorflow_datasets/core/community/dataset_sources_test.py && coverage xml -o coverage.xml --fail-under=0"
mutation_run_command = "mut.py --target tensorflow_datasets.core.community.dataset_sources --unit-test tensorflow_datasets.core.community.dataset_sources_test --runner pytest --report mutation_report.yaml"
mutation_run_command_fallback = "mut.py --target tensorflow_datasets/core/community/dataset_sources.py --unit-test tensorflow_datasets/core/community/dataset_sources_test.py --runner pytest --report mutation_report.yaml"
coverage_report_path = "coverage.xml"
coverage_report_type = "cobertura"
mutation_report_path = "mutation_report.yaml"
mutation_report_type = "mutpy"

[coverage]
coverage = 81.0
original_coverage = 81.0
mutation_kill_rate = 0
original_mutation_kill_rate = 0.0
covered_lines = [ 17, 18, 19, 21, 22, 25, 26, 35, 36, 38, 39, 41, 42, 43, 44, 45, 52, 54, 55, 57, 63,]
missed_lines = [ 50, 77, 78, 79, 82,]

[input_info]
test_file_path = "tensorflow_datasets/core/community/dataset_sources_test.py"
focal_file_path = "tensorflow_datasets/core/community/dataset_sources.py"
test_file_url = "https://github.com/tensorflow/datasets/blob/5afdc02a1a6ce1a5ded7e2395c7a3498216936bb/tensorflow_datasets/core/community/dataset_sources_test.py"
focal_file_url = "https://github.com/tensorflow/datasets/blob/5afdc02a1a6ce1a5ded7e2395c7a3498216936bb/tensorflow_datasets/core/community/dataset_sources.py"
first_commit_date = "2021-01-19"
last_commit_date = "2025-06-02"
test_file_content = "\n\n\nimport os\n\nfrom tensorflow_datasets.core import github_api\nfrom tensorflow_datasets.core.community import dataset_sources\n\n\ndef test_dataset_source():\n  uri = 'github://owner/repo/tree/master/.../audio/gtzan/gtzan.py'\n  src = dataset_sources.DatasetSource.from_json(uri)\n  src_json = src.to_json()\n\n\ndef test_dataset_source_multifiles():\n  json_input = {\n      'root_path': 'github://owner/repo/tree/master/.../audio/gtzan',\n      'filenames': ['checksums.tsv', 'gtzan.py'],\n  }\n  src = dataset_sources.DatasetSource.from_json(json_input)\n  src_json = src.to_json()"
