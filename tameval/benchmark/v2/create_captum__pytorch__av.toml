[meta]
task = "create"
scenario = "extend_test_file"

[lang_info]
lang = "Python"
python_cfg_file = "pyproject.toml"

[repo_info]
repository = "pytorch/captum"
sha = "aff7603051094012c9cf1a739a0538c38a6986b2"

[run_info]
docker_image = "python:3"
volumes_to_mount = [ "{proj_path}:/app", "{host}/.m2:/.m2", "{host}/.cache/pip:/.pip_cache", "{host}/.cache/go-build:/.go_cache", "{proj_path}/_HOME_/go:/go",]
docker_wrap = "sudo docker run --rm -w /app -e PATH=_HOME_/.local/bin:$PATH -e PYTHONUSERBASE=_HOME_/.local/ -v {proj_path}:/app -v {host}/.m2:/.m2 -v {host}/.cache/pip:/.pip_cache -v {host}/.cache/go-build:/.go_cache -v {proj_path}/_HOME_/go:/go {img} sh -c '{cmd}'"
env = [ "PATH=_HOME_/.local/bin:$PATH", "PYTHONUSERBASE=_HOME_/.local/",]
prebuild_command = "(pip install .[all,test] && pip install git+https://github.com/Klema17/mutpy.git && pip install coverage pytest pytest_cov covdefaults Cython mock ddt pytest_mock testfixtures)"
test_run_command = "coverage run --include=captum/_utils/av.py -m pytest -q --junit-xml=test_output.xml tests/utils/test_av.py && coverage xml -o coverage.xml --fail-under=0"
mutation_run_command = "mut.py --target captum._utils.av --unit-test tests.utils.test_av --runner pytest --report mutation_report.yaml"
mutation_run_command_fallback = "mut.py --target captum/_utils/av.py --unit-test tests/utils/test_av.py --runner pytest --report mutation_report.yaml"
coverage_report_path = "coverage.xml"
coverage_report_type = "cobertura"
mutation_report_path = "mutation_report.yaml"
mutation_report_type = "mutpy"

[coverage]
coverage = 91.0
original_coverage = 91.0
mutation_kill_rate = 59.0
original_mutation_kill_rate = 59.0
covered_lines = [ 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 18, 30, 35, 44, 71, 75, 78, 80, 81, 82, 83, 84, 86, 87, 89, 91, 94, 95, 100, 102, 103, 108, 111, 113, 115, 117, 118, 135, 137, 141, 143, 147, 149, 150, 183, 184, 187, 189, 190, 224, 225, 226, 227, 229, 232, 234, 235, 239, 240, 241, 242, 244, 245, 278, 280, 281, 282, 284, 288, 289, 319, 320, 322, 323, 324, 325, 342, 344, 345, 383, 391, 394, 395, 396, 399, 401, 402, 410, 412, 414, 419, 420, 464, 471, 472, 473, 483, 484, 485, 488, 490, 491, 499, 505, 507,]
missed_lines = [ 92, 109, 230, 327, 328, 335, 336, 339, 340, 411, 486,]

[input_info]
test_file_path = "tests/utils/test_av.py"
focal_file_path = "captum/_utils/av.py"
test_file_url = "https://github.com/pytorch/captum/blob/aff7603051094012c9cf1a739a0538c38a6986b2/tests/utils/test_av.py"
focal_file_url = "https://github.com/pytorch/captum/blob/aff7603051094012c9cf1a739a0538c38a6986b2/captum/_utils/av.py"
first_commit_date = "2021-10-05"
last_commit_date = "2025-06-27"
test_file_content = "# pyre-unsafe\nimport glob\nimport tempfile\nfrom datetime import datetime\nfrom typing import cast, List\n\nimport torch\nfrom captum._utils.av import AV\nfrom captum.testing.helpers import BaseTest\nfrom captum.testing.helpers.basic import assertTensorAlmostEqual\nfrom captum.testing.helpers.basic_models import BasicLinearReLULinear\nfrom torch.utils.data import DataLoader, Dataset\n\nDEFAULT_IDENTIFIER = \"default_identifier\"\n\n\nclass RangeDataset(Dataset):\n    def __init__(self, low, high, num_features) -> None:\n        self.samples = (\n            torch.arange(start=low, end=high, dtype=torch.float)\n            .repeat(num_features, 1)\n            .transpose(1, 0)\n        )\n\n    def __len__(self) -> int:\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        return self.samples[idx]\n\n\nclass Test(BaseTest):\n    def test_exists_without_version(self) -> None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            av_0 = torch.randn(64, 16)\n            self.assertFalse(AV.exists(tmpdir, \"dummy\", \"layer1.0.conv1\"))\n\n            AV.save(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv1\", av_0, \"0\")\n            self.assertTrue(\n                AV.exists(\n                    tmpdir,\n                    \"dummy\",\n                    DEFAULT_IDENTIFIER,\n                    \"layer1.0.conv1\",\n                )\n            )\n\n    def test_exists_with_version(self) -> None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            idf1 = str(int(datetime.now().microsecond))\n            idf2 = \"idf2\"\n            av_0 = torch.randn(64, 16)\n\n            self.assertFalse(AV.exists(tmpdir, \"dummy\", \"layer1.0.conv1\", idf1))\n            self.assertFalse(AV.exists(tmpdir, \"dummy\", \"layer1.0.conv1\", idf2))\n\n            AV.save(tmpdir, \"dummy\", idf1, \"layer1.0.conv1\", av_0, \"0\")\n            self.assertTrue(AV.exists(tmpdir, \"dummy\", idf1, \"layer1.0.conv1\"))\n            self.assertFalse(AV.exists(tmpdir, \"dummy\", idf2, \"layer1.0.conv1\"))\n\n            AV.save(tmpdir, \"dummy\", idf2, \"layer1.0.conv1\", av_0, \"0\")\n            self.assertTrue(AV.exists(tmpdir, \"dummy\", idf2, \"layer1.0.conv1\"))\n\n    def test_av_save_two_layers(self) -> None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            av_0 = torch.randn(64, 16)\n\n            AV.save(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv1\", av_0, \"0\")\n            self.assertTrue(\n                AV.exists(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv1\")\n            )\n            self.assertFalse(\n                AV.exists(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv2\")\n            )\n\n            # experimenting with adding to another layer\n            av_1 = torch.randn(64, 16)\n            AV.save(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv2\", av_1, \"0\")\n            self.assertTrue(\n                AV.exists(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv2\")\n            )\n\n    def test_av_save_multi_layer(self) -> None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            av_0 = torch.randn(64, 16)\n            av_1 = torch.randn(64, 16)\n            av_2 = torch.randn(64, 16)\n\n            model_path = AV._assemble_model_dir(tmpdir, \"dummy\")\n\n            # save first layer\n            AV.save(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv1\", av_0, \"0\")\n            self.assertEqual(len(glob.glob(model_path + \"*\")), 1)\n\n            # add two new layers at once\n            AV.save(\n                tmpdir,\n                \"dummy\",\n                DEFAULT_IDENTIFIER,\n                [\"layer1.0.conv2\", \"layer1.1.conv1\"],\n                [av_1, av_2],\n                \"0\",\n            )\n\n            self.assertEqual(len(glob.glob(model_path + \"/*/*/*\")), 3)\n\n            # overwrite the first saved layer\n            AV.save(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv1\", av_0, \"0\")\n            self.assertEqual(len(glob.glob(model_path + \"/*/*/*\")), 3)\n\n            # save a new version of the first layer\n            idf1 = str(int(datetime.now().microsecond))\n            self.assertFalse(AV.exists(tmpdir, \"dummy\", idf1, \"layer1.0.conv1\"))\n            AV.save(tmpdir, \"dummy\", idf1, \"layer1.0.conv1\", av_0, \"0\")\n\n            self.assertTrue(AV.exists(tmpdir, \"dummy\", idf1, \"layer1.0.conv1\"))\n            self.assertEqual(len(glob.glob(model_path + \"/*/*/*\")), 4)\n\n    def test_av_save_multiple_batches_per_layer(self) -> None:\n        def save_and_assert_batch(layer_path, total_num_batches, batch, n_batch_name):\n            # save n-th batch and verify the number of saved batches\n            AV.save(\n                tmpdir,\n                model_id,\n                DEFAULT_IDENTIFIER,\n                \"layer1.0.conv1\",\n                batch,\n                n_batch_name,\n            )\n            self.assertEqual(\n                len(glob.glob(\"/\".join([layer_path, \"*.pt\"]))),\n                total_num_batches,\n            )\n            self.assertTrue(\n                AV.exists(\n                    tmpdir, model_id, DEFAULT_IDENTIFIER, \"layer1.0.conv1\", n_batch_name\n                )\n            )\n\n        with tempfile.TemporaryDirectory() as tmpdir:\n            b0 = torch.randn(64, 16)\n            b1 = torch.randn(64, 16)\n            b2 = torch.randn(64, 16)\n\n            model_id = \"dummy\"\n            model_path = AV._assemble_model_dir(tmpdir, model_id)\n\n            layer_path = AV._assemble_file_path(\n                model_path, DEFAULT_IDENTIFIER, \"layer1.0.conv1\"\n            )\n\n            # save first batch and verify the number of saved batches\n            save_and_assert_batch(layer_path, 1, b0, \"0\")\n\n            # save second batch and verify the number of saved batches\n            save_and_assert_batch(layer_path, 2, b1, \"1\")\n\n            # save third batch and verify the number of saved batches\n            save_and_assert_batch(layer_path, 3, b2, \"2\")\n\n    def test_av_load_multiple_batches_per_layer(self) -> None:\n        def save_load_and_assert_batch(\n            layer_path, total_num_batches, batch, n_batch_name\n        ):\n            # save n-th batch and verify the number of saved batches\n            AV.save(\n                tmpdir,\n                model_id,\n                DEFAULT_IDENTIFIER,\n                \"layer1.0.conv1\",\n                batch,\n                n_batch_name,\n            )\n            loaded_dataset = AV.load(\n                tmpdir, model_id, DEFAULT_IDENTIFIER, \"layer1.0.conv1\", n_batch_name\n            )\n\n            assertTensorAlmostEqual(self, next(iter(loaded_dataset)), batch, 0.0)\n\n            loaded_dataset_for_layer = AV.load(\n                tmpdir, model_id, DEFAULT_IDENTIFIER, \"layer1.0.conv1\"\n            )\n            self.assertEqual(\n                loaded_dataset_for_layer.__len__(),\n                total_num_batches,\n            )\n\n        with tempfile.TemporaryDirectory() as tmpdir:\n            b0 = torch.randn(64, 16)\n            b1 = torch.randn(64, 16)\n            b2 = torch.randn(64, 16)\n\n            model_id = \"dummy\"\n            model_path = AV._assemble_model_dir(tmpdir, model_id)\n\n            layer_path = AV._assemble_file_path(\n                model_path, DEFAULT_IDENTIFIER, \"layer1.0.conv1\"\n            )\n\n            # save first batch and verify the number of saved batches\n            save_load_and_assert_batch(layer_path, 1, b0, \"0\")\n\n            # save second batch and verify the number of saved batches\n            save_load_and_assert_batch(layer_path, 2, b1, \"1\")\n\n            # save third batch and verify the number of saved batches\n            save_load_and_assert_batch(layer_path, 3, b2, \"2\")\n\n    def test_av_load_non_saved_layer(self) -> None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            model_id = \"dummy\"\n            with self.assertRaises(RuntimeError) as context:\n                AV.load(tmpdir, model_id)\n            self.assertTrue(\n                (\n                    f\"Activation vectors for model {model_id} \"\n                    f\"was not found at path {tmpdir}\"\n                )\n                == str(context.exception)\n            )\n\n    def test_av_load_one_batch(self) -> None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            av_0 = torch.randn(64, 16)\n            av_1 = torch.randn(36, 16)\n            avs = [av_0, av_1]\n\n            # add av_0 to the list of activations\n            model_id = \"dummy\"\n            with self.assertRaises(RuntimeError) as context:\n                AV.load(tmpdir, model_id)\n            self.assertTrue(\n                (\n                    f\"Activation vectors for model {model_id} \"\n                    f\"was not found at path {tmpdir}\"\n                )\n                == str(context.exception)\n            )\n\n            AV.save(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv1\", av_0, \"0\")\n            model_id = \"dummy\"\n            dataset = AV.load(tmpdir, model_id, identifier=DEFAULT_IDENTIFIER)\n\n            for i, av in enumerate(DataLoader(cast(Dataset, dataset))):\n                assertTensorAlmostEqual(self, av, avs[i].unsqueeze(0))\n\n            # add av_1 to the list of activations\n            dataloader_2 = DataLoader(\n                cast(\n                    Dataset,\n                    AV.load(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv2\"),\n                )\n            )\n            self.assertEqual(len(dataloader_2), 0)\n\n            AV.save(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv2\", av_1, \"0\")\n            dataset = AV.load(tmpdir, \"dummy\", identifier=DEFAULT_IDENTIFIER)\n\n            dataloader = DataLoader(cast(Dataset, dataset))\n            self.assertEqual(len(dataloader), 2)\n            for i, av in enumerate(dataloader):\n                assertTensorAlmostEqual(self, av, avs[i].unsqueeze(0))\n\n    def test_av_load_all_identifiers_one_layer(self) -> None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            av_0 = torch.randn(64, 16)\n            av_1 = torch.randn(36, 16)\n            av_2 = torch.randn(16, 16)\n            av_3 = torch.randn(4, 16)\n            avs = [av_1, av_2, av_3]\n\n            idf1, idf2, idf3 = \"idf1\", \"idf2\", \"idf3\"\n\n            AV.save(tmpdir, \"dummy\", DEFAULT_IDENTIFIER, \"layer1.0.conv1\", av_0, \"0\")\n            dataloader = DataLoader(\n                cast(Dataset, AV.load(tmpdir, \"dummy\", identifier=DEFAULT_IDENTIFIER))\n            )\n            self.assertEqual(len(dataloader), 1)\n\n            # add activations for another layer\n            AV.save(tmpdir, \"dummy\", idf1, \"layer1.0.conv2\", av_1, \"0\")\n            AV.save(tmpdir, \"dummy\", idf2, \"layer1.0.conv2\", av_2, \"0\")\n            AV.save(tmpdir, \"dummy\", idf3, \"layer1.0.conv2\", av_3, \"0\")\n            dataloader_layer = DataLoader(\n                cast(\n                    Dataset,\n                    AV.load(\n                        tmpdir,\n                        \"dummy\",\n                        layer=\"layer1.0.conv2\",\n                    ),\n                )\n            )\n\n            self.assertEqual(len(dataloader_layer), 3)\n            for i, av in enumerate(dataloader_layer):\n                assertTensorAlmostEqual(self, av, avs[i].unsqueeze(0))\n\n            dataloader = DataLoader(cast(Dataset, AV.load(tmpdir, \"dummy\")))\n            self.assertEqual(len(dataloader), 4)\n\n    def test_av_load_all_layers_one_identifier(self) -> None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            av_01 = torch.randn(36, 16)\n            av_02 = torch.randn(16, 16)\n            av_03 = torch.randn(4, 16)\n            avs_0 = [av_01, av_02, av_03]\n\n            av_11 = torch.randn(36, 16)\n            av_12 = torch.randn(16, 16)\n            av_13 = torch.randn(4, 16)\n            avs_1 = [av_11, av_12, av_13]\n\n            idf1, idf2 = \"idf1\", \"idf2\"\n\n            AV.save(\n                tmpdir,\n                \"dummy\",\n                idf1,\n                [\"layer1.0.conv1\", \"layer1.0.conv2\", \"layer1.1.conv1\"],\n                avs_0,\n                \"0\",\n            )\n            dataloader = DataLoader(cast(Dataset, AV.load(tmpdir, \"dummy\")))\n            self.assertEqual(len(dataloader), 3)\n\n            AV.save(\n                tmpdir,\n                \"dummy\",\n                idf2,\n                [\"layer1.0.conv1\", \"layer1.0.conv2\", \"layer1.1.conv1\"],\n                avs_1,\n                \"0\",\n            )\n            dataloader = DataLoader(cast(Dataset, AV.load(tmpdir, \"dummy\")))\n            self.assertEqual(len(dataloader), 6)\n\n            # check activations for idf1\n            dataloader_layer = DataLoader(\n                cast(Dataset, AV.load(tmpdir, \"dummy\", identifier=idf1))\n            )\n            self.assertEqual(len(dataloader_layer), 3)\n\n            for i, av in enumerate(dataloader_layer):\n                assertTensorAlmostEqual(self, av, avs_0[i].unsqueeze(0))\n\n            # check activations for idf2\n            dataloader_layer = DataLoader(\n                cast(Dataset, AV.load(tmpdir, \"dummy\", identifier=idf2))\n            )\n            self.assertEqual(len(dataloader_layer), 3)\n            for i, av in enumerate(dataloader_layer):\n                assertTensorAlmostEqual(self, av, avs_1[i].unsqueeze(0))\n\n    def test_av_sort_files(self) -> None:\n        files = [\"resnet50-cifar-3000\", \"resnet50-cifar-1000\", \"resnet50-cifar-2000\"]\n        exp_files = [\n            \"resnet50-cifar-1000\",\n            \"resnet50-cifar-2000\",\n            \"resnet50-cifar-3000\",\n        ]\n        files = AV.sort_files(files)\n\n        self.assertEqual(files, exp_files)\n\n        files = [\"resnet50-cifar-0900\", \"resnet50-cifar-0000\", \"resnet50-cifar-1000\"]\n        exp_files = [\n            \"resnet50-cifar-0000\",\n            \"resnet50-cifar-0900\",\n            \"resnet50-cifar-1000\",\n        ]\n        files = AV.sort_files(files)\n        self.assertEqual(files, exp_files)\n\n        files = [\"resnet50-cifar-100\", \"resnet50-cifar-90\", \"resnet50-cifar-3000\"]\n        exp_files = [\n            \"resnet50-cifar-90\",\n            \"resnet50-cifar-100\",\n            \"resnet50-cifar-3000\",\n        ]\n        files = AV.sort_files(files)\n        self.assertEqual(files, exp_files)\n\n        files = [\n            \"av/pretrained-net-0/fc1-src10-710935.pt\",\n            \"av/pretrained-net-0/fc1-src11-755317.pt\",\n            \"av/pretrained-net-0/fc3-src2-655646.pt\",\n            \"av/pretrained-net-0/fc1-src9-952381.pt\",\n            \"av/pretrained-net-0/conv2-src7-811286.pt\",\n            \"av/pretrained-net-0/fc1-src10-176141.pt\",\n            \"av/pretrained-net-0/conv11-src9-384927.pt\",\n        ]\n        exp_files = [\n            \"av/pretrained-net-0/conv2-src7-811286.pt\",\n            \"av/pretrained-net-0/conv11-src9-384927.pt\",\n            \"av/pretrained-net-0/fc1-src9-952381.pt\",\n            \"av/pretrained-net-0/fc1-src10-176141.pt\",\n            \"av/pretrained-net-0/fc1-src10-710935.pt\",\n            \"av/pretrained-net-0/fc1-src11-755317.pt\",\n            \"av/pretrained-net-0/fc3-src2-655646.pt\",\n        ]\n        files = AV.sort_files(files)\n        self.assertEqual(files, exp_files)\n\n    def test_generate_activation(self) -> None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            num_features = 4\n            low, high = 0, 16\n            mymodel = BasicLinearReLULinear(num_features)\n            mydata = RangeDataset(low, high, num_features)\n            layers: List[str] = [\n                value[0] for value in mymodel.named_modules() if value[0]\n            ]\n\n            # First AV generation on last 2 layers\n            inputs = torch.stack((mydata[1], mydata[8], mydata[14]))\n            AV._compute_and_save_activations(\n                tmpdir, mymodel, \"model_id_1\", layers[1:], inputs, \"test\", \"0\"\n            )\n\n            av_test = AV._construct_file_search(tmpdir, \"model_id_1\", identifier=\"test\")\n            av_test = glob.glob(av_test)\n            self.assertEqual(len(av_test), len(layers[1:]))\n\n            # Second AV generation on first 2 layers.\n            # Second layer overlaps with existing activations, should be loaded.\n            inputs = torch.stack((mydata[0], mydata[7], mydata[13]))\n            AV._compute_and_save_activations(\n                tmpdir, mymodel, \"model_id_1\", layers[:2], inputs, \"test\", \"0\"\n            )\n\n            av_test = AV._construct_file_search(tmpdir, \"model_id_1\", identifier=\"test\")\n            av_test = glob.glob(av_test)\n            self.assertEqual(len(av_test), len(layers))\n\n    def test_generate_dataset_activations(self) -> None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            num_features = 4\n            low, high = 0, 16\n            batch_size = high // 2\n            mymodel = BasicLinearReLULinear(num_features)\n            mydata = RangeDataset(low, high, num_features)\n            layers: List[str] = [\n                value[0] for value in mymodel.named_modules() if value[0]\n            ]\n\n            # First AV generation on last 2 layers\n            layer_AVDatasets = AV.generate_dataset_activations(\n                tmpdir,\n                mymodel,\n                \"model_id1\",\n                layers[1:],\n                DataLoader(mydata, batch_size, shuffle=False),\n                \"src\",\n                return_activations=True,\n            )\n\n            av_src = AV._construct_file_search(\n                tmpdir, model_id=\"model_id1\", identifier=\"src\"\n            )\n            av_src = glob.glob(av_src)\n            self.assertEqual(len(av_src), high / batch_size * len(layers[1:]))\n\n            self.assertTrue(isinstance(layer_AVDatasets, list))\n            layer_AVDatasets = cast(list, layer_AVDatasets)\n            self.assertEqual(len(layer_AVDatasets), len(layers[1:]))\n            for layer_AVDataset in layer_AVDatasets:\n                self.assertEqual(len(layer_AVDataset), high / batch_size)\n\n            # Second AV generation on first 2 layers.\n            # Second layer overlaps with existing activations, should be loaded.\n            layer_AVDatasets = AV.generate_dataset_activations(\n                tmpdir,\n                mymodel,\n                \"model_id1\",\n                layers[:2],\n                DataLoader(mydata, batch_size, shuffle=False),\n                \"src\",\n                return_activations=True,\n            )\n\n            av_src = AV._construct_file_search(\n                tmpdir, model_id=\"model_id1\", identifier=\"src\"\n            )\n            av_src = glob.glob(av_src)\n            self.assertEqual(len(av_src), high / batch_size * len(layers))\n\n            self.assertTrue(isinstance(layer_AVDatasets, list))\n            layer_AVDatasets = cast(list, layer_AVDatasets)\n            self.assertEqual(len(layer_AVDatasets), len(layers[:2]))\n            for layer_AVDataset in layer_AVDatasets:\n                self.assertEqual(len(layer_AVDataset), high / batch_size)\n\n            # check that if return_activations is False, None is returned\n            self.assertIsNone(\n                AV.generate_dataset_activations(\n                    tmpdir,\n                    mymodel,\n                    \"model_id1\",\n                    layers[:2],\n                    DataLoader(mydata, batch_size, shuffle=False),\n                    \"src\",\n                    return_activations=False,\n                )\n            )\n\n    def test_equal_activation(self) -> None:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            num_features = 4\n            low, high = 0, 16\n            mymodel = BasicLinearReLULinear(num_features)\n            mydata = RangeDataset(low, high, num_features)\n            layers: List[str] = [\n                value[0] for value in mymodel.named_modules() if value[0]\n            ]\n\n            # First AV generation on last 2 layers\n            test_input = mydata[1].unsqueeze(0)\n            model_id = \"id_1\"\n            identifier = \"test\"\n            num_id = \"0\"\n            AV._compute_and_save_activations(\n                tmpdir, mymodel, model_id, layers[2], test_input, identifier, num_id\n            )\n            act_dataset = AV.load(tmpdir, model_id, identifier, layers[2], num_id)\n            _layer_act = [act.squeeze(0) for act in DataLoader(act_dataset)]\n            act = torch.cat(_layer_act)\n            out = mymodel(test_input)\n            assertTensorAlmostEqual(self, out, act)\n"
