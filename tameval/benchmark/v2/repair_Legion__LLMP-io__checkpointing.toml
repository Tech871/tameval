[meta]
task = "repair"
scenario = "repair_no_new_covered_logic"

[lang_info]
lang = "Python"
python_version = "3.11"
python_cfg_file = "pyproject.toml"

[repo_info]
repository = "LLMP-io/Legion"
sha = "ba7764e32f6e9ff9b93439ee62df5da5d26608f9"

[run_info]
docker_image = "python:3.11"
volumes_to_mount = [ "{proj_path}:/app", "{host}/.m2:/.m2", "{host}/.cache/pip:/.pip_cache", "{host}/.cache/go-build:/.go_cache", "{proj_path}/_HOME_/go:/go",]
docker_wrap = "sudo docker run --rm -w /app -e PATH=_HOME_/.local/bin:$PATH -e PYTHONUSERBASE=_HOME_/.local/ -v {proj_path}:/app -v {host}/.m2:/.m2 -v {host}/.cache/pip:/.pip_cache -v {host}/.cache/go-build:/.go_cache -v {proj_path}/_HOME_/go:/go {img} sh -c '{cmd}'"
env = [ "PATH=_HOME_/.local/bin:$PATH", "PYTHONUSERBASE=_HOME_/.local/",]
prebuild_command = "pip install -r requirements.txt && (pip install .[all,test] && pip install git+https://github.com/Klema17/mutpy.git && pip install coverage pytest pytest_cov covdefaults Cython mock ddt pytest_mock testfixtures)"
test_run_command = "coverage run --include=legion/graph/checkpointing.py -m pytest -q --junit-xml=test_output.xml tests/graph/test_checkpointing.py && coverage xml -o coverage.xml --fail-under=0"
mutation_run_command = "mut.py --target legion.graph.checkpointing --unit-test tests.graph.test_checkpointing --runner pytest --report mutation_report.yaml"
mutation_run_command_fallback = "mut.py --target legion/graph/checkpointing.py --unit-test tests/graph/test_checkpointing.py --runner pytest --report mutation_report.yaml"
coverage_report_path = "coverage.xml"
coverage_report_type = "cobertura"
mutation_report_path = "mutation_report.yaml"
mutation_report_type = "mutpy"

[coverage]
coverage = 98.0
original_coverage = 98.0
mutation_kill_rate = 0
original_mutation_kill_rate = nan
covered_lines = [ 0, 1, 2, 3, 5, 7, 8, 11, 14, 15, 16, 18, 24, 27, 28, 30, 45, 50, 51, 52, 53, 54, 57, 58, 64, 81, 84, 85, 86, 87, 88, 89, 90, 91, 94, 96, 102, 106, 107, 110, 111, 113, 115, 130, 133, 134, 136, 137, 141, 142, 144, 146, 159, 160,]
missed_lines = [ 131,]

[input_info]
test_file_path = "tests/graph/test_checkpointing.py"
focal_file_path = "legion/graph/checkpointing.py"
test_file_url = "https://github.com/LLMP-io/Legion/blob/ba7764e32f6e9ff9b93439ee62df5da5d26608f9/tests/graph/test_checkpointing.py"
focal_file_url = "https://github.com/LLMP-io/Legion/blob/ba7764e32f6e9ff9b93439ee62df5da5d26608f9/legion/graph/checkpointing.py"
first_commit_date = "2025-01-07"
last_commit_date = "2025-01-08"
test_file_content = "import json\nimport logging\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\nimport pytest\n\nfrom legion.graph.channels import LastValue\nfrom legion.graph.checkpointing import GraphCheckpoint, GraphCheckpointer\nfrom legion.graph.state import GraphState\nfrom legion.memory.base import MemoryDump, MemoryProvider, ThreadState\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    handlers=[\n        logging.StreamHandler(sys.stdout)\n    ]\n)\nlogger = logging.getLogger(__name__)\n\nclass MockMemoryProvider(MemoryProvider):\n\n    def __init__(self):\n        self._threads: Dict[str, Dict[str, Any]] = {}\n        self._states: Dict[str, Dict[str, Dict[str, Any]]] = {}\n        self.logger = logging.getLogger(__name__ + \".MockMemoryProvider\")\n\n    async def create_thread(\n        self,\n        entity_id: str,\n        parent_thread_id: Optional[str] = None\n    ) -> str:\n        thread_id = f\"thread_{len(self._threads)}\"\n        self._threads[thread_id] = {\n            \"entity_id\": entity_id,\n            \"parent_thread_id\": parent_thread_id\n        }\n        self.logger.debug(f\"Created thread {thread_id} for entity {entity_id}\")\n        return thread_id\n\n    async def save_state(\n        self,\n        entity_id: str,\n        thread_id: str,\n        state: Dict[str, Any]\n    ) -> None:\n        if thread_id not in self._states:\n            self._states[thread_id] = {}\n        self._states[thread_id][entity_id] = state\n        self.logger.debug(f\"Saved state for thread {thread_id}, entity {entity_id}: {state}\")\n\n    async def load_state(\n        self,\n        entity_id: str,\n        thread_id: str\n    ) -> Optional[Dict[str, Any]]:\n        state = self._states.get(thread_id, {}).get(entity_id)\n        self.logger.debug(f\"Loading state for thread {thread_id}, entity {entity_id}: {state}\")\n        return state\n\n    async def delete_thread(\n        self,\n        thread_id: str,\n        recursive: bool = True\n    ) -> None:\n        if thread_id in self._threads:\n            del self._threads[thread_id]\n        if thread_id in self._states:\n            del self._states[thread_id]\n\n    async def list_threads(\n        self,\n        entity_id: Optional[str] = None\n    ) -> List[ThreadState]:\n        threads = []\n        for thread_id, thread in self._threads.items():\n            if not entity_id or thread[\"entity_id\"] == entity_id:\n                threads.append(ThreadState(\n                    thread_id=thread_id,\n                    entity_id=thread[\"entity_id\"],\n                    parent_thread_id=thread[\"parent_thread_id\"],\n                    created_at=datetime.now(),\n                    updated_at=datetime.now()\n                ))\n        return threads\n\n    async def _create_memory_dump(self) -> MemoryDump:\n        threads = {}\n        for thread_id, thread in self._threads.items():\n            threads[thread_id] = ThreadState(\n                thread_id=thread_id,\n                entity_id=thread[\"entity_id\"],\n                parent_thread_id=thread[\"parent_thread_id\"],\n                created_at=datetime.now(),\n                updated_at=datetime.now()\n            )\n\n        return MemoryDump(\n            threads=threads,\n            store=self._states\n        )\n\n    async def _restore_memory_dump(self, dump: MemoryDump) -> None:\n        self._threads.clear()\n        self._states.clear()\n\n        for thread_id, thread in dump.threads.items():\n            self._threads[thread_id] = {\n                \"entity_id\": thread.entity_id,\n                \"parent_thread_id\": thread.parent_thread_id\n            }\n\n        self._states = dump.store\n\n@pytest.fixture\ndef temp_checkpoint_file(tmp_path):\n    return tmp_path / \"checkpoint.json\"\n\n@pytest.fixture\ndef memory_provider():\n    return MockMemoryProvider()\n\n@pytest.fixture\ndef graph_state():\n    state = GraphState()\n    channel = state.create_channel(LastValue, \"test\", type_hint=str)\n    channel.set(\"test_value\")\n    state.set_global_state({\"key\": \"value\"})\n    return state\n\ndef test_checkpoint_model():\n    checkpoint = GraphCheckpoint(\n        state_data={\"test\": \"data\"}\n    )\n\n    assert checkpoint.version == \"1.0\"\n    assert isinstance(checkpoint.created_at, datetime)\n    assert checkpoint.state_data == {\"test\": \"data\"}\n\n@pytest.mark.asyncio\nasync def test_file_checkpointing(graph_state, temp_checkpoint_file):\n    checkpointer = GraphCheckpointer()\n    await checkpointer.save_checkpoint(graph_state, path=temp_checkpoint_file)\n    assert temp_checkpoint_file.exists()\n    with temp_checkpoint_file.open(\"r\") as f:\n        data = json.load(f)\n        assert \"version\" in data\n        assert \"state_data\" in data\n    new_state = GraphState()\n    await checkpointer.load_checkpoint(new_state, path=temp_checkpoint_file)\n    assert new_state.get_channel(\"test\").get() == \"test_value\"\n    assert new_state.get_global_state() == {\"key\": \"value\"}\n\n@pytest.mark.asyncio\nasync def test_memory_provider_checkpointing_alternative(graph_state, memory_provider):\n    logger.info(\"Starting memory provider checkpointing test\")\n    checkpointer = GraphCheckpointer(memory_provider)\n\n    original_graph_id = graph_state.graph_id\n    thread_id = await memory_provider.create_thread(original_graph_id)\n    logger.debug(f\"Created thread {thread_id} for graph {original_graph_id}\")\n\n    checkpoint_data = graph_state.checkpoint()\n    logger.debug(f\"Graph state checkpoint data: {checkpoint_data}\")\n\n    await checkpointer.save_checkpoint(graph_state, thread_id=thread_id)\n    logger.debug(\"Saved checkpoint\")\n    state = await memory_provider.load_state(original_graph_id, thread_id)\n    logger.debug(f\"Raw state in memory provider: {state}\")\n    new_state = GraphState()\n    logger.debug(\"Created new graph state for restoration\")\n\n    try:\n        await checkpointer.load_checkpoint(\n            new_state,\n            thread_id=thread_id,\n            graph_id=original_graph_id\n        )\n        logger.debug(\"Successfully loaded checkpoint\")\n    except Exception as e:\n        logger.error(f\"Failed to load checkpoint: {str(e)}\", exc_info=True)\n        raise\n    channel_value = new_state.get_channel(\"test\").get()\n    global_state = new_state.get_global_state()\n    logger.debug(f\"Restored channel value: {channel_value}\")\n    logger.debug(f\"Restored global state: {global_state}\")\n\n    assert channel_value == \"test_value\"\n    assert global_state == {\"key\": \"value\"}\n\n@pytest.mark.asyncio\nasync def test_memory_provider_checkpointing_duplicate(graph_state, memory_provider):\n    logger.info(\"Starting memory provider checkpointing test\")\n    checkpointer = GraphCheckpointer(memory_provider)\n\n    original_graph_id = graph_state.graph_id\n    thread_id = await memory_provider.create_thread(original_graph_id)\n    logger.debug(f\"Created thread {thread_id} for graph {original_graph_id}\")\n\n    checkpoint_data = graph_state.checkpoint()\n    logger.debug(f\"Graph state checkpoint data: {checkpoint_data}\")\n\n    await checkpointer.save_checkpoint(graph_state, thread_id=thread_id)\n    logger.debug(\"Saved checkpoint\")\n    state = await memory_provider.load_state(original_graph_id, thread_id)\n    logger.debug(f\"Raw state in memory provider: {state}\")\n    new_state = GraphState()\n    logger.debug(\"Created new graph state for restoration\")\n\n    try:\n        await checkpointer.load_checkpoint(\n            new_state,\n            thread_id=thread_id,\n            graph_id=original_graph_id\n        )\n        logger.debug(\"Successfully loaded checkpoint\")\n    except Exception as e:\n        logger.error(f\"Failed to load checkpoint: {str(e)}\", exc_info=True)\n        raise\n    channel_value = new_state.get_channel(\"test\").get_value()\n    global_state = new_state.get_global_state()\n    logger.debug(f\"Restored channel value: {channel_value}\")\n    logger.debug(f\"Restored global state: {global_state}\")\n\n    assert channel_value == \"test_value\"\n    assert global_state == {\"key\": \"value\"}\n\n@pytest.mark.asyncio\nasync def test_checkpoint_listing(graph_state, memory_provider):\n    checkpointer = GraphCheckpointer(memory_provider)\n    thread_id1 = await memory_provider.create_thread(graph_state.graph_id)\n    thread_id2 = await memory_provider.create_thread(graph_state.graph_id)\n\n    await checkpointer.save_checkpoint(graph_state, thread_id=thread_id1)\n    await checkpointer.save_checkpoint(graph_state, thread_id=thread_id2)\n    checkpoints = await checkpointer.list_checkpoints(graph_state.graph_id)\n\n    assert len(checkpoints) == 2\n    assert thread_id1 in checkpoints\n    assert thread_id2 in checkpoints\n    assert all(isinstance(cp, GraphCheckpoint) for cp in checkpoints.values())\n\n@pytest.mark.asyncio\nasync def test_checkpoint_deletion(graph_state, memory_provider):\n    checkpointer = GraphCheckpointer(memory_provider)\n    thread_id = await memory_provider.create_thread(graph_state.graph_id)\n    await checkpointer.save_checkpoint(graph_state, thread_id=thread_id)\n    await checkpointer.delete_checkpoint(thread_id)\n    checkpoints = await checkpointer.list_checkpoints(graph_state.graph_id)\n    assert thread_id not in checkpoints\n\n@pytest.mark.asyncio\nasync def test_checkpoint_not_found(graph_state):\n    checkpointer = GraphCheckpointer()\n\n    with pytest.raises(ValueError, match=\"No checkpoint found\"):\n        await checkpointer.load_checkpoint(\n            graph_state,\n            path=Path(\"nonexistent.json\")\n        )\n\n@pytest.mark.asyncio\nasync def test_multiple_save_locations(graph_state, temp_checkpoint_file, memory_provider):\n    logger.info(\"Starting multiple save locations test\")\n    checkpointer = GraphCheckpointer(memory_provider)\n\n    original_graph_id = graph_state.graph_id\n    thread_id = await memory_provider.create_thread(original_graph_id)\n    logger.debug(f\"Created thread {thread_id}\")\n    await checkpointer.save_checkpoint(\n        graph_state,\n        path=temp_checkpoint_file,\n        thread_id=thread_id\n    )\n    logger.debug(f\"Saved checkpoint to file {temp_checkpoint_file} and thread {thread_id}\")\n    with temp_checkpoint_file.open(\"r\") as f:\n        file_data = json.load(f)\n        logger.debug(f\"File checkpoint data: {file_data}\")\n    mem_state = await memory_provider.load_state(original_graph_id, thread_id)\n    logger.debug(f\"Memory provider state: {mem_state}\")\n    new_state1 = GraphState()\n    await checkpointer.load_checkpoint(new_state1, path=temp_checkpoint_file)\n    logger.debug(\"Loaded file checkpoint\")\n    new_state2 = GraphState()\n    try:\n        await checkpointer.load_checkpoint(\n            new_state2,\n            thread_id=thread_id,\n            graph_id=original_graph_id\n        )\n        logger.debug(\"Loaded memory provider checkpoint\")\n    except Exception as e:\n        logger.error(f\"Failed to load memory provider checkpoint: {str(e)}\", exc_info=True)\n        raise\n\n    assert new_state1.get_channel(\"test\").get() == \"test_value\"\n    assert new_state2.get_channel(\"test\").get() == \"test_value\"\n\nif __name__ == \"__main__\":\n    logging.basicConfig(\n        level=logging.DEBUG,\n        format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n        handlers=[\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n    args = [\n        __file__,\n        \"-v\",\n        \"--tb=short\",\n        \"-p\", \"no:warnings\",\n        \"-p\", \"asyncio\",\n        \"--log-cli-level=DEBUG\",\n        \"-s\"\n    ]\n    sys.exit(pytest.main(args))"
