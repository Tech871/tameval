[meta]
task = "update"
scenario = "update_test"

[lang_info]
lang = "Python"
python_cfg_file = "pyproject.toml"

[repo_info]
repository = "pytorch/captum"
sha = "aff7603051094012c9cf1a739a0538c38a6986b2"

[run_info]
docker_image = "python:3"
volumes_to_mount = [ "{proj_path}:/app", "{host}/.m2:/.m2", "{host}/.cache/pip:/.pip_cache", "{host}/.cache/go-build:/.go_cache", "{proj_path}/_HOME_/go:/go",]
docker_wrap = "sudo docker run --rm -w /app -e PATH=_HOME_/.local/bin:$PATH -e PYTHONUSERBASE=_HOME_/.local/ -v {proj_path}:/app -v {host}/.m2:/.m2 -v {host}/.cache/pip:/.pip_cache -v {host}/.cache/go-build:/.go_cache -v {proj_path}/_HOME_/go:/go {img} sh -c '{cmd}'"
env = [ "PATH=_HOME_/.local/bin:$PATH", "PYTHONUSERBASE=_HOME_/.local/",]
prebuild_command = "(pip install .[all,test] && pip install git+https://github.com/Klema17/mutpy.git && pip install coverage pytest pytest_cov covdefaults Cython mock ddt pytest_mock testfixtures)"
test_run_command = "coverage run --include=captum/_utils/gradient.py -m pytest -q --junit-xml=test_output.xml tests/utils/test_gradient.py && coverage xml -o coverage.xml --fail-under=0"
mutation_run_command = "mut.py --target captum._utils.gradient --unit-test tests.utils.test_gradient --runner pytest --report mutation_report.yaml"
mutation_run_command_fallback = "mut.py --target captum/_utils/gradient.py --unit-test tests/utils/test_gradient.py --runner pytest --report mutation_report.yaml"
coverage_report_path = "coverage.xml"
coverage_report_type = "cobertura"
mutation_report_path = "mutation_report.yaml"
mutation_report_type = "mutpy"

[coverage]
coverage = 13.0
original_coverage = 55.0
mutation_kill_rate = nan
original_mutation_kill_rate = 38.0
covered_lines = [ 3, 4, 5, 6, 7, 20, 21, 27, 28, 34, 35, 38, 79, 102, 142, 199, 256, 363, 384, 469, 598, 774, 808, 822, 896,]
missed_lines = [ 47, 50, 51, 52, 53, 54, 57, 60, 61, 68, 69, 70, 75, 76, 90, 93, 96, 97, 98, 99, 125, 127, 131, 132, 138, 139, 149, 150, 151, 152, 155, 165, 166, 209, 280, 281, 285, 293, 298, 299, 300, 302, 303, 304, 305, 306, 310, 311, 312, 313, 314, 315, 319, 322, 324, 328, 330, 331, 332, 333, 334, 338, 341, 350, 352, 353, 355, 356, 358, 359, 360, 379, 380, 381, 399, 403, 407, 409, 416, 503, 505, 506, 513, 517, 518, 519, 522, 525, 530, 531, 533, 668, 671, 681, 686, 691, 695, 696, 707, 723, 724, 730, 736, 737, 738, 739, 740, 746, 747, 748, 752, 755, 756, 757, 759, 760, 763, 766, 771, 785, 792, 801, 803, 809, 810, 811, 816, 819, 856, 857, 858, 860, 861, 862, 863, 864, 866, 871, 872, 873, 875, 876, 877, 891, 893, 941, 942, 943, 944, 945, 946, 948, 949, 953, 954, 956, 959, 960, 964, 965, 970, 971, 975, 977, 978, 982, 984, 991, 992, 993, 1005, 1007,]

[input_info]
test_file_path = "tests/utils/test_gradient.py"
focal_file_path = "captum/_utils/gradient.py"
test_file_url = "https://github.com/pytorch/captum/blob/aff7603051094012c9cf1a739a0538c38a6986b2/tests/utils/test_gradient.py"
focal_file_url = "https://github.com/pytorch/captum/blob/aff7603051094012c9cf1a739a0538c38a6986b2/captum/_utils/gradient.py"
first_commit_date = "2020-05-27"
last_commit_date = "2025-08-14"
test_file_content = "#!/usr/bin/env python3\n\n# pyre-unsafe\n\nimport unittest\nfrom typing import List, Tuple\n\nimport torch\nfrom captum._utils.gradient import (\n    apply_gradient_requirements,\n    compute_gradients,\n    compute_layer_gradients_and_eval,\n    undo_gradient_requirements,\n)\nfrom packaging import version\nfrom tests.helpers import BaseTest\nfrom tests.helpers.basic import assertTensorAlmostEqual\nfrom tests.helpers.basic_models import (\n    BasicModel,\n    BasicModel2,\n    BasicModel4_MultiArgs,\n    BasicModel5_MultiArgs,\n    BasicModel6_MultiTensor,\n    BasicModel_MultiLayer,\n)\n\n\nclass Test(BaseTest):\n    def test_apply_gradient_reqs(self) -> None:\n        initial_grads = [False, True, False]\n        test_tensor = torch.tensor([[6.0]], requires_grad=True)\n        test_tensor.grad = torch.tensor([[7.0]])\n        test_tensor_tuple = (torch.tensor([[5.0]]), test_tensor, torch.tensor([[7.0]]))\n        out_mask = apply_gradient_requirements(test_tensor_tuple)\n        for i in range(len(test_tensor_tuple)):\n            self.assertTrue(test_tensor_tuple[i].requires_grad)\n            self.assertEqual(out_mask[i], initial_grads[i])\n\n    def test_undo_gradient_reqs(self) -> None:\n        initial_grads = [False, True, False]\n        test_tensor = torch.tensor([[6.0]], requires_grad=True)\n        test_tensor.grad = torch.tensor([[7.0]])\n        test_tensor_tuple = (\n            torch.tensor([[6.0]], requires_grad=True),\n            test_tensor,\n            torch.tensor([[7.0]], requires_grad=True),\n        )\n        undo_gradient_requirements(test_tensor_tuple, initial_grads)\n        for i in range(len(test_tensor_tuple)):\n            self.assertEqual(test_tensor_tuple[i].requires_grad, initial_grads[i])\n\n    def test_gradient_basic(self) -> None:\n        model = BasicModel()\n        input = torch.tensor([[5.0]], requires_grad=True)\n        input.grad = torch.tensor([[9.0]])\n        grads = compute_gradients(model, input)[0]\n        assertTensorAlmostEqual(self, grads, [[0.0]], delta=0.01, mode=\"max\")\n        # Verify grad attribute is not altered\n        assertTensorAlmostEqual(self, input.grad, [[9.0]], delta=0.0, mode=\"max\")\n\n    def test_gradient_basic_2(self) -> None:\n        model = BasicModel()\n        input = torch.tensor([[-3.0]], requires_grad=True)\n        input.grad = torch.tensor([[14.0]])\n        grads = compute_gradients(model, input)[0]\n        assertTensorAlmostEqual(self, grads, [[1.0]], delta=0.01, mode=\"max\")\n        # Verify grad attribute is not altered\n        assertTensorAlmostEqual(self, input.grad, [[14.0]], delta=0.0, mode=\"max\")\n\n    def test_gradient_multiinput(self) -> None:\n        model = BasicModel6_MultiTensor()\n        input1 = torch.tensor([[-3.0, -5.0]], requires_grad=True)\n        input2 = torch.tensor([[-5.0, 2.0]], requires_grad=True)\n        grads = compute_gradients(model, (input1, input2))\n        assertTensorAlmostEqual(self, grads[0], [[0.0, 1.0]], delta=0.01, mode=\"max\")\n        assertTensorAlmostEqual(self, grads[1], [[0.0, 1.0]], delta=0.01, mode=\"max\")\n\n    def test_gradient_additional_args(self) -> None:\n        model = BasicModel4_MultiArgs()\n        input1 = torch.tensor([[10.0]], requires_grad=True)\n        input2 = torch.tensor([[8.0]], requires_grad=True)\n        grads = compute_gradients(model, (input1, input2), additional_forward_args=(2,))\n        assertTensorAlmostEqual(self, grads[0], [[1.0]], delta=0.01, mode=\"max\")\n        assertTensorAlmostEqual(self, grads[1], [[-0.5]], delta=0.01, mode=\"max\")\n\n    def test_gradient_additional_args_2(self) -> None:\n        model = BasicModel5_MultiArgs()\n        input1 = torch.tensor([[-10.0]], requires_grad=True)\n        input2 = torch.tensor([[6.0]], requires_grad=True)\n        grads = compute_gradients(\n            model, (input1, input2), additional_forward_args=([3, -4],)\n        )\n        assertTensorAlmostEqual(self, grads[0], [[0.0]], delta=0.01, mode=\"max\")\n        assertTensorAlmostEqual(self, grads[1], [[4.0]], delta=0.01, mode=\"max\")\n\n    def test_gradient_target_int(self) -> None:\n        model = BasicModel2()\n        input1 = torch.tensor([[4.0, -1.0]], requires_grad=True)\n        input2 = torch.tensor([[2.0, 5.0]], requires_grad=True)\n        grads0 = compute_gradients(model, (input1, input2), target_ind=0)\n        grads1 = compute_gradients(model, (input1, input2), target_ind=1)\n        assertTensorAlmostEqual(self, grads0[0], [[1.0, 0.0]], delta=0.01, mode=\"max\")\n        assertTensorAlmostEqual(self, grads0[1], [[-1.0, 0.0]], delta=0.01, mode=\"max\")\n        assertTensorAlmostEqual(self, grads1[0], [[0.0, 0.0]], delta=0.01, mode=\"max\")\n        assertTensorAlmostEqual(self, grads1[1], [[0.0, 0.0]], delta=0.01, mode=\"max\")\n\n    def test_gradient_target_list(self) -> None:\n        model = BasicModel2()\n        input1 = torch.tensor([[4.0, -1.0], [3.0, 10.0]], requires_grad=True)\n        input2 = torch.tensor([[2.0, -5.0], [-2.0, 1.0]], requires_grad=True)\n        grads = compute_gradients(model, (input1, input2), target_ind=[0, 1])\n        assertTensorAlmostEqual(\n            self,\n            grads[0],\n            [[1.0, 0.0], [0.0, 1.0]],\n            delta=0.01,\n            mode=\"max\",\n        )\n        assertTensorAlmostEqual(\n            self,\n            grads[1],\n            [[-1.0, 0.0], [0.0, -1.0]],\n            delta=0.01,\n            mode=\"max\",\n        )\n\n    def test_gradient_target_tuple(self) -> None:\n        model = BasicModel()\n        input = torch.tensor(\n            [[[4.0, 2.0], [-1.0, -2.0]], [[3.0, -4.0], [10.0, 5.0]]], requires_grad=True\n        )\n        grads = compute_gradients(model, input, target_ind=(0, 1))[0]\n        assertTensorAlmostEqual(\n            self,\n            grads,\n            [[[0.0, 0.0], [0.0, 0.0]], [[0.0, 1.0], [0.0, 0.0]]],\n            delta=0.01,\n            mode=\"max\",\n        )\n\n    def test_gradient_target_listtuple(self) -> None:\n        model = BasicModel()\n        input = torch.tensor(\n            [[[4.0, 2.0], [-1.0, -2.0]], [[3.0, -4.0], [10.0, 5.0]]], requires_grad=True\n        )\n        target: List[Tuple[int, ...]] = [(1, 1), (0, 1)]\n        grads = compute_gradients(model, input, target_ind=target)[0]\n        assertTensorAlmostEqual(\n            self,\n            grads,\n            [[[0.0, 0.0], [0.0, 1.0]], [[0.0, 1.0], [0.0, 0.0]]],\n            delta=0.01,\n            mode=\"max\",\n        )\n\n    def test_gradient_inplace(self) -> None:\n        model = BasicModel_MultiLayer(inplace=True)\n        input = torch.tensor([[1.0, 6.0, -3.0]], requires_grad=True)\n        grads = compute_gradients(model, input, target_ind=0)[0]\n        assertTensorAlmostEqual(self, grads, [[3.0, 3.0, 3.0]], delta=0.01, mode=\"max\")\n\n    def test_layer_gradient_linear0(self) -> None:\n        model = BasicModel_MultiLayer()\n        input = torch.tensor([[5.0, -11.0, 23.0]], requires_grad=True)\n        grads, eval = compute_layer_gradients_and_eval(\n            model, model.linear0, input, target_ind=0\n        )\n        assertTensorAlmostEqual(\n            self, grads[0], [[4.0, 4.0, 4.0]], delta=0.01, mode=\"max\"\n        )\n        assertTensorAlmostEqual(\n            self,\n            eval[0],\n            [[5.0, -11.0, 23.0]],\n            delta=0.01,\n            mode=\"max\",\n        )\n\n    def test_layer_gradient_linear1(self) -> None:\n        model = BasicModel_MultiLayer()\n        input = torch.tensor([[5.0, 2.0, 1.0]], requires_grad=True)\n        grads, eval = compute_layer_gradients_and_eval(\n            model, model.linear1, input, target_ind=1\n        )\n        assertTensorAlmostEqual(\n            self,\n            grads[0],\n            [[0.0, 1.0, 1.0, 1.0]],\n            delta=0.01,\n            mode=\"max\",\n        )\n        assertTensorAlmostEqual(\n            self,\n            eval[0],\n            [[-2.0, 9.0, 9.0, 9.0]],\n            delta=0.01,\n            mode=\"max\",\n        )\n\n    def test_layer_gradient_linear1_inplace(self) -> None:\n        model = BasicModel_MultiLayer(inplace=True)\n        input = torch.tensor([[5.0, 2.0, 1.0]], requires_grad=True)\n        grads, eval = compute_layer_gradients_and_eval(\n            model, model.linear1, input, target_ind=1\n        )\n        assertTensorAlmostEqual(\n            self,\n            grads[0],\n            [[0.0, 1.0, 1.0, 1.0]],\n            delta=0.01,\n            mode=\"max\",\n        )\n        assertTensorAlmostEqual(\n            self,\n            eval[0],\n            [[-2.0, 9.0, 9.0, 9.0]],\n            delta=0.01,\n            mode=\"max\",\n        )\n\n    def test_layer_gradient_relu_input_inplace(self) -> None:\n        model = BasicModel_MultiLayer(inplace=True)\n        input = torch.tensor([[5.0, 2.0, 1.0]], requires_grad=True)\n        grads, eval = compute_layer_gradients_and_eval(\n            model, model.relu, input, target_ind=1, attribute_to_layer_input=True\n        )\n        assertTensorAlmostEqual(\n            self,\n            grads[0],\n            [[0.0, 1.0, 1.0, 1.0]],\n            delta=0.01,\n            mode=\"max\",\n        )\n        assertTensorAlmostEqual(\n            self,\n            eval[0],\n            [[-2.0, 9.0, 9.0, 9.0]],\n            delta=0.01,\n            mode=\"max\",\n        )\n\n    def test_layer_gradient_output(self) -> None:\n        model = BasicModel_MultiLayer()\n        input = torch.tensor([[5.0, 2.0, 1.0]], requires_grad=True)\n        grads, eval = compute_layer_gradients_and_eval(\n            model, model.linear2, input, target_ind=1\n        )\n        assertTensorAlmostEqual(self, grads[0], [[0.0, 1.0]], delta=0.01, mode=\"max\")\n        assertTensorAlmostEqual(self, eval[0], [[26.0, 28.0]], delta=0.01, mode=\"max\")\n\n    def test_layer_gradient_unused_layer(self) -> None:\n        if version.parse(torch.__version__) < version.parse(\"2.1.0\"):\n            raise unittest.SkipTest(\n                \"Skipping unused layed gradient test since it is not supported \"\n                \"by torch version < 2.1\"\n            )\n\n        model = BasicModel_MultiLayer(multi_input_module=True)\n        input = torch.tensor([[5.0, 2.0, 1.0]], requires_grad=True)\n        grads, eval = compute_layer_gradients_and_eval(\n            model,\n            [model.linear1, model.relu],\n            input,\n            target_ind=1,\n            grad_kwargs={\"materialize_grads\": True},\n        )\n        assertTensorAlmostEqual(\n            self, grads[0][0], [[0.0, 1.0, 1.0, 1.0]], delta=0, mode=\"max\"\n        )\n        assertTensorAlmostEqual(\n            self, eval[0][0], [[-2.0, 9.0, 9.0, 9.0]], delta=0, mode=\"max\"\n        )"
