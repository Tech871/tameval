[meta]
task = "repair"
scenario = "repair_no_new_covered_logic"

[lang_info]
lang = "Python"
python_version = "3.13"
python_cfg_file = "pyproject.toml"

[repo_info]
repository = "Franblueee/torchmil"
sha = "733d8fafb5c020313cca7fe3e5c8ce9c28d13a09"

[run_info]
docker_image = "python:3.13"
volumes_to_mount = [ "{proj_path}:/app", "{host}/.m2:/.m2", "{host}/.cache/pip:/.pip_cache", "{host}/.cache/go-build:/.go_cache", "{proj_path}/_HOME_/go:/go",]
docker_wrap = "sudo docker run --rm -w /app -e PATH=_HOME_/.local/bin:$PATH -e PYTHONUSERBASE=_HOME_/.local/ -v {proj_path}:/app -v {host}/.m2:/.m2 -v {host}/.cache/pip:/.pip_cache -v {host}/.cache/go-build:/.go_cache -v {proj_path}/_HOME_/go:/go {img} sh -c '{cmd}'"
env = [ "PATH=_HOME_/.local/bin:$PATH", "PYTHONUSERBASE=_HOME_/.local/",]
prebuild_command = "(pip install .[all,test] && pip install git+https://github.com/Klema17/mutpy.git && pip install coverage pytest pytest_cov covdefaults Cython mock ddt pytest_mock testfixtures)"
test_run_command = "coverage run --include=torchmil/models/prob_smooth_abmil.py -m pytest -q --junit-xml=test_output.xml tests/models/test_prob_smooth_abmil.py && coverage xml -o coverage.xml --fail-under=0"
mutation_run_command = "mut.py --target torchmil.models.prob_smooth_abmil --unit-test tests.models.test_prob_smooth_abmil --runner pytest --report mutation_report.yaml"
mutation_run_command_fallback = "mut.py --target torchmil/models/prob_smooth_abmil.py --unit-test tests/models/test_prob_smooth_abmil.py --runner pytest --report mutation_report.yaml"
coverage_report_path = "coverage.xml"
coverage_report_type = "cobertura"
mutation_report_path = "mutation_report.yaml"
mutation_report_type = "mutpy"

[coverage]
coverage = 98.0
original_coverage = 98.0
mutation_kill_rate = 0
original_mutation_kill_rate = nan
covered_lines = [ 0, 1, 3, 4, 7, 55, 75, 76, 78, 79, 80, 83, 90, 92, 118, 120, 124, 125, 126, 128, 130, 131, 133, 135, 136, 137, 139, 140, 141, 142, 144, 145, 146, 148, 150, 151, 153, 155, 172, 175, 177, 178, 179, 181, 183, 203, 208, 209, 225, 235, 252, 253, 255,]
missed_lines = [ 82,]

[input_info]
test_file_path = "tests/models/test_prob_smooth_abmil.py"
focal_file_path = "torchmil/models/prob_smooth_abmil.py"
test_file_url = "https://github.com/Franblueee/torchmil/blob/733d8fafb5c020313cca7fe3e5c8ce9c28d13a09/tests/models/test_prob_smooth_abmil.py"
focal_file_url = "https://github.com/Franblueee/torchmil/blob/733d8fafb5c020313cca7fe3e5c8ce9c28d13a09/torchmil/models/prob_smooth_abmil.py"
first_commit_date = "2025-01-16"
last_commit_date = "2025-07-22"
test_file_content = "import torch\n\nfrom torchmil.models.prob_smooth_abmil import ProbSmoothABMIL, SmoothABMIL\ndef create_dummy_data(batch_size=2, bag_size=3, feat_dim=5):\n    X = torch.randn(batch_size, bag_size, feat_dim)\n    Y = torch.randint(0, 2, (batch_size,))\n    adj = torch.eye(bag_size).unsqueeze(0).repeat(batch_size, 1, 1)\n    mask = torch.ones(batch_size, bag_size, dtype=torch.bool)\n    return X, Y, adj, mask\nclass TestProbSmoothABMIL:\n    def test_forward(self):\n        model = ProbSmoothABMIL(in_shape=(5,))\n        X, _, adj, mask = create_dummy_data()\n        output = model(X)\n        assert output.shape == (X.shape[0],)\n\n        model.eval()\n        output_with_att = model(X, return_att=True)\n        assert isinstance(output_with_att, tuple)\n        assert len(output_with_att) == 2\n        assert output_with_att[0].shape == (X.shape[0],)\n        assert output_with_att[1].shape == (X.shape[0], X.shape[1])\n\n        output_with_samples_att = model(X, return_att=True, return_samples=True)\n        assert isinstance(output_with_samples_att, tuple)\n        assert len(output_with_samples_att) == 2\n        assert output_with_samples_att[0].shape == (\n            X.shape[0],\n            model.pool.n_samples_test,\n        )\n        assert output_with_samples_att[1].shape == (\n            X.shape[0],\n            X.shape[1],\n            model.pool.n_samples_test,\n        )\n\n        output_with_kl = model(X, adj, return_kl_div=True)\n        assert isinstance(output_with_kl, tuple)\n        assert len(output_with_kl) == 2\n        assert output_with_kl[0].shape == (X.shape[0],)\n        assert isinstance(output_with_kl[1], torch.Tensor)\n\n        output_with_all = model(\n            X, adj, mask, return_att=True, return_samples=True, return_kl_div=True\n        )\n        assert isinstance(output_with_all, tuple)\n        assert len(output_with_all) == 3\n        assert output_with_all[0].shape == (X.shape[0], model.pool.n_samples_test)\n        assert output_with_all[1].shape == (\n            X.shape[0],\n            X.shape[1],\n            model.pool.n_samples_test,\n        )\n        assert isinstance(output_with_all[2], torch.Tensor)\n\n    def test_forward_alternative(self):\n        model = ProbSmoothABMIL(in_shape=(5,))\n        X, _, adj, mask = create_dummy_data()\n        output = model(X, adj, mask)\n        assert output.shape == (X.shape[0],)\n\n        model.eval()\n        output_with_att = model(X, adj, mask, return_att=True)\n        assert isinstance(output_with_att, tuple)\n        assert len(output_with_att) == 2\n        assert output_with_att[0].shape == (X.shape[0],)\n        assert output_with_att[1].shape == (X.shape[0], X.shape[1])\n\n        output_with_samples_att = model(X, adj, mask, return_att=True, return_samples=True)\n        assert isinstance(output_with_samples_att, tuple)\n        assert len(output_with_samples_att) == 2\n        assert output_with_samples_att[0].shape == (\n            X.shape[0],\n            model.pool.n_samples_test,\n        )\n        assert output_with_samples_att[1].shape == (\n            X.shape[0],\n            X.shape[1],\n            model.pool.n_samples_test,\n        )\n\n        output_with_kl = model(X, adj, mask, return_kl_div=True)\n        assert isinstance(output_with_kl, tuple)\n        assert len(output_with_kl) == 2\n        assert output_with_kl[0].shape == (X.shape[0],)\n        assert isinstance(output_with_kl[1], torch.Tensor)\n\n        output_with_all = model(\n            X, adj, mask, return_att=True, return_samples=True, return_kl_div=True\n        )\n        assert isinstance(output_with_all, tuple)\n        assert len(output_with_all) == 3\n        assert output_with_all[0].shape == (X.shape[0], model.pool.n_samples_test)\n        assert output_with_all[1].shape == (\n            X.shape[0],\n            X.shape[1],\n            model.pool.n_samples_test,\n        )\n        assert isinstance(output_with_all[2], torch.Tensor)\n\n    def test_compute_loss(self):\n        model = ProbSmoothABMIL(in_shape=(5,))\n        X, Y, adj, mask = create_dummy_data()\n        Y_pred, loss_dict = model.compute_loss(Y, X, adj, mask)\n        assert Y_pred.shape == (X.shape[0],)\n        assert isinstance(loss_dict, dict)\n        assert \"BCEWithLogitsLoss\" in loss_dict\n        assert \"KLDiv\" in loss_dict\n        assert isinstance(loss_dict[\"BCEWithLogitsLoss\"], torch.Tensor)\n        assert isinstance(loss_dict[\"KLDiv\"], torch.Tensor)\n\n    def test_compute_loss_variant(self):\n        model = ProbSmoothABMIL(in_shape=(5,))\n        X, Y, adj, mask = create_dummy_data()\n        Y_pred, loss_dict = model.compute_loss(Y, X, adj, mask=mask)\n        assert Y_pred.shape == (X.shape[0],)\n        assert isinstance(loss_dict, dict)\n        assert \"BCEWithLogitsLoss\" in loss_dict\n        assert \"KLDiv\" in loss_dict\n        assert isinstance(loss_dict[\"BCEWithLogitsLoss\"], torch.Tensor)\n        assert isinstance(loss_dict[\"KLDiv\"], torch.Tensor)\n\n    def test_predict(self):\n        model = ProbSmoothABMIL(in_shape=(5,))\n        model.eval()\n        X, _, _, mask = create_dummy_data()\n        Y_pred, att_val = model.predict(X, mask)\n        assert Y_pred.shape == (X.shape[0],)\n        assert att_val.shape == (X.shape[0], X.shape[1])\n\n        Y_pred_no_inst = model.predict(X, mask, return_inst_pred=False)\n        assert Y_pred_no_inst.shape == (X.shape[0],)\n\n        Y_pred_samples, att_val_samples = model.predict(\n            X, mask, return_inst_pred=True, return_samples=True\n        )\n        assert Y_pred_samples.shape == (X.shape[0], model.pool.n_samples_test)\n        assert att_val_samples.shape == (\n            X.shape[0],\n            X.shape[1],\n            model.pool.n_samples_test,\n        )\nclass TestSmoothABMIL:\n    def test_compute_loss(self):\n        model = SmoothABMIL(in_shape=(5,))\n        X, Y, adj, mask = create_dummy_data()\n        Y_pred, loss_dict = model.compute_loss(Y, X, adj, mask)\n        assert Y_pred.shape == (X.shape[0],)\n        assert isinstance(loss_dict, dict)\n        assert \"BCEWithLogitsLoss\" in loss_dict\n        assert \"DirEnergy\" in loss_dict\n        assert isinstance(loss_dict[\"BCEWithLogitsLoss\"], torch.Tensor)\n        assert isinstance(loss_dict[\"DirEnergy\"], torch.Tensor)\n        assert \"KLDiv\" not in loss_dict\n\n    def test_compute_loss_alt(self):\n        model = SmoothABMIL(in_shape=(5,))\n        X, Y, adj, mask = create_dummy_data()\n        Y_pred, loss_dict = model.compute_loss(Y=Y, X=X, adj=adj, mask=mask)\n        assert Y_pred.shape == (X.shape[0],)\n        assert isinstance(loss_dict, dict)\n        assert \"BCEWithLogitsLoss\" in loss_dict\n        assert \"DirEnergy\" in loss_dict\n        assert isinstance(loss_dict[\"BCEWithLogitsLoss\"], torch.Tensor)\n        assert isinstance(loss_dict[\"DirEnergy\"], torch.Tensor)\n        assert \"KLDiv\" not in loss_dict"
