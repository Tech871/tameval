[meta]
task = "repair"
scenario = "repair_syntax_error"

[lang_info]
lang = "Python"
python_version = "3.13"
python_cfg_file = "requirements.txt"

[repo_info]
repository = "github/issue-metrics"
sha = "23689ee936e1c52ad48581667f483140c24224f1"

[run_info]
docker_image = "python:3.13"
volumes_to_mount = [ "{proj_path}:/app", "{host}/.m2:/.m2", "{host}/.cache/pip:/.pip_cache", "{host}/.cache/go-build:/.go_cache", "{proj_path}/_HOME_/go:/go",]
docker_wrap = "sudo docker run --rm -w /app -e PATH=_HOME_/.local/bin:$PATH -e PYTHONUSERBASE=_HOME_/.local/ -v {proj_path}:/app -v {host}/.m2:/.m2 -v {host}/.cache/pip:/.pip_cache -v {host}/.cache/go-build:/.go_cache -v {proj_path}/_HOME_/go:/go {img} sh -c '{cmd}'"
env = [ "PATH=_HOME_/.local/bin:$PATH", "PYTHONUSERBASE=_HOME_/.local/",]
prebuild_command = "pip install -r requirements-test.txt && pip install -r requirements.txt && (pip install git+https://github.com/Klema17/mutpy.git && pip install coverage pytest pytest_cov covdefaults Cython mock ddt pytest_mock testfixtures)"
test_run_command = "coverage run --include=markdown_writer.py -m pytest -q --junit-xml=test_output.xml test_markdown_writer.py && coverage xml -o coverage.xml --fail-under=0"
mutation_run_command = "mut.py --target markdown_writer --unit-test test_markdown_writer --runner pytest --report mutation_report.yaml"
mutation_run_command_fallback = "mut.py --target markdown_writer.py --unit-test test_markdown_writer.py --runner pytest --report mutation_report.yaml"
coverage_report_path = "coverage.xml"
coverage_report_type = "cobertura"
mutation_report_path = "mutation_report.yaml"
mutation_report_type = "mutpy"

[coverage]
coverage = 0.0
original_coverage = 95.0
mutation_kill_rate = 0.0
original_mutation_kill_rate = 89.0
covered_lines = []
missed_lines = []

[input_info]
test_file_path = "test_markdown_writer.py"
focal_file_path = "markdown_writer.py"
test_file_url = "https://github.com/github/issue-metrics/blob/23689ee936e1c52ad48581667f483140c24224f1/test_markdown_writer.py"
focal_file_url = "https://github.com/github/issue-metrics/blob/23689ee936e1c52ad48581667f483140c24224f1/markdown_writer.py"
first_commit_date = "2023-06-24"
last_commit_date = "2025-02-28"
test_file_content = "\"A module containing unit tests for the write_to_markdown function in the markdown_writer module.\n\nClasses:\n    TestWriteToMarkdown: A class to test the write_to_markdown function with mock data.\n    TestWriteToMarkdownWithEnv: A class to test the write_to_markdown function with\n        environment variables set.\n\n\"\"\"\n\nimport os\nimport unittest\nfrom datetime import timedelta\nfrom unittest.mock import call, mock_open, patch\n\nfrom classes import IssueWithMetrics\nfrom markdown_writer import write_to_markdown\n\n\n@patch.dict(\n    os.environ,\n    {\n        \"SEARCH_QUERY\": \"is:open repo:user/repo\",\n        \"GH_TOKEN\": \"test_token\",\n        \"DRAFT_PR_TRACKING\": \"True\",\n        \"HIDE_CREATED_AT\": \"False\",\n    },\n)\nclass TestWriteToMarkdown(unittest.TestCase):\n    \"\"\"Test the write_to_markdown function.\"\"\"\n\n    maxDiff = None\n\n    def test_write_to_markdown(self):\n        \"\"\"Test that write_to_markdown writes the correct markdown file.\n\n        This test creates a list of mock GitHub issues with time to first response\n        attributes, calls write_to_markdown with the list and the average time to\n        first response, time to close and checks that the function writes the correct\n        markdown file.\n\n        \"\"\"\n        # Create mock data\n        issues_with_metrics = [\n            IssueWithMetrics(\n                title=\"Issue 1\",\n                html_url=\"https://github.com/user/repo/issues/1\",\n                author=\"alice\",\n                created_at=timedelta(days=-5),\n                time_to_first_response=timedelta(days=1),\n                time_to_close=timedelta(days=2),\n                time_to_answer=timedelta(days=3),\n                time_in_draft=timedelta(days=1),\n                labels_metrics={\"bug\": timedelta(days=4)},\n            ),\n            IssueWithMetrics(\n                title=\"Issue 2\\r\",\n                html_url=\"https://github.com/user/repo/issues/2\",\n                author=\"bob\",\n                created_at=timedelta(days=-5),\n                time_to_first_response=timedelta(days=3),\n                time_to_close=timedelta(days=4),\n                time_to_answer=timedelta(days=5),\n                time_in_draft=timedelta(days=1),\n                labels_metrics={\"bug\": timedelta(days=2)},\n            ),\n        ]\n        time_to_first_response = {\n            \"avg\": timedelta(days=2),\n            \"med\": timedelta(days=2),\n            \"90p\": timedelta(days=2),\n        }\n        time_to_close = {\n            \"avg\": timedelta(days=3),\n            \"med\": timedelta(days=3),\n            \"90p\": timedelta(days=3),\n        }\n        time_to_answer = {\n            \"avg\": timedelta(days=4),\n            \"med\": timedelta(days=4),\n            \"90p\": timedelta(days=4),\n        }\n        time_in_draft = {\n            \"avg\": timedelta(days=1),\n            \"med\": timedelta(days=1),\n            \"90p\": timedelta(days=1),\n        }\n        time_in_labels = {\n            \"avg\": {\"bug\": \"1 day, 12:00:00\"},\n            \"med\": {\"bug\": \"1 day, 12:00:00\"},\n            \"90p\": {\"bug\": \"1 day, 12:00:00\"},\n        }\n\n        num_issues_opened = 2\n        num_issues_closed = 1\n        num_mentor_count = 5\n\n        # Call the function\n        write_to_markdown(\n            issues_with_metrics=issues_with_metrics,\n            average_time_to_first_response=time_to_first_response,\n            average_time_to_close=time_to_close,\n            average_time_to_answer=time_to_answer,\n            average_time_in_draft=time_in_draft,\n            average_time_in_labels=time_in_labels,\n            num_issues_opened=num_issues_opened,\n            num_issues_closed=num_issues_closed,\n            num_mentor_count=num_mentor_count,\n            labels=[\"bug\"],\n            search_query=\"is:issue is:open label:bug\",\n            report_title=\"Issue Metrics\",\n            output_file=\"issue_metrics.md\",\n            ghe=\"\",\n        )\n\n        # Check that the function writes the correct markdown file\n        with open(\"issue_metrics.md\", \"r\", encoding=\"utf-8\") as file:\n            content = file.read()\n        expected_content = (\n            \"# Issue Metrics\\n\\n\"\n            \"| Metric | Average | Median | 90th percentile |\\n\"\n            \"| --- | --- | --- | ---: |\\n\"\n            \"| Time to first response | 2 days, 0:00:00 | 2 days, 0:00:00 | 2 days, 0:00:00 |\\n\"\n            \"| Time to close | 3 days, 0:00:00 | 3 days, 0:00:00 | 3 days, 0:00:00 |\\n\"\n            \"| Time to answer | 4 days, 0:00:00 | 4 days, 0:00:00 | 4 days, 0:00:00 |\\n\"\n            \"| Time in draft | 1 day, 0:00:00 | 1 day, 0:00:00 | 1 day, 0:00:00 |\\n\"\n            \"| Time spent in bug | 1 day, 12:00:00 | 1 day, 12:00:00 | 1 day, 12:00:00 |\\n\"\n            \"\\n\"\n            \"| Metric | Count |\\n\"\n            \"| --- | ---: |\\n\"\n            \"| Number of items that remain open | 2 |\\n\"\n            \"| Number of items closed | 1 |\\n\"\n            \"| Number of most active mentors | 5 |\\n\"\n            \"| Total number of items created | 2 |\\n\\n\"\n            \"| Title | URL | Author | Time to first response | Time to close |\"\n            \" Time to answer | Time in draft | Time spent in bug | Created At |\\n\"\n            \"| --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n\"\n            \"| Issue 1 | https://github.com/user/repo/issues/1 | [alice](https://github.com/alice) | 1 day, 0:00:00 | \"\n            \"2 days, 0:00:00 | 3 days, 0:00:00 | 1 day, 0:00:00 | 4 days, 0:00:00 | -5 days, 0:00:00 |\\n\"\n            \"| Issue 2 | https://github.com/user/repo/issues/2 | [bob](https://github.com/bob) | 3 days, 0:00:00 | \"\n            \"4 days, 0:00:00 | 5 days, 0:00:00 | 1 day, 0:00:00 | 2 days, 0:00:00 | -5 days, 0:00:00 |\\n\\n\"\n            \"_This report was generated with the [Issue Metrics Action](https://github.com/github/issue-metrics)_\\n\"\n            \"Search query used to find these items: `is:issue is:open label:bug`\\n\"\n        )\n        self.assertEqual(content, expected_content)\n        os.remove(\"issue_metrics.md\")\n\n    def test_write_to_markdown_with_vertical_bar_in_title(self):\n        \"\"\"Test that write_to_markdown writes the correct markdown file when the title contains a vertical bar.\n\n        This test creates a list of mock GitHub issues (one of which contains a vertical\n        bar in the title) with time to first response attributes, calls write_to_markdown\n        with the list and the average time to first response, time to close and checks\n        that the function writes the correct markdown file.\n\n        \"\"\"\n        # Create mock data\n        issues_with_metrics = [\n            IssueWithMetrics(\n                title=\"Issue 1\",\n                html_url=\"https://github.com/user/repo/issues/1\",\n                author=\"alice\",\n                created_at=timedelta(days=-5),\n                time_to_first_response=timedelta(days=1),\n                time_to_close=timedelta(days=2),\n                time_to_answer=timedelta(days=3),\n                time_in_draft=timedelta(days=1),\n                labels_metrics={\"bug\": timedelta(days=1)},\n            ),\n            IssueWithMetrics(\n                title=\"feat| Issue 2\",  # title contains a vertical bar\n                html_url=\"https://github.com/user/repo/issues/2\",\n                author=\"bob\",\n                created_at=timedelta(days=-5),\n                time_to_first_response=timedelta(days=3),\n                time_to_close=timedelta(days=4),\n                time_to_answer=timedelta(days=5),\n                labels_metrics={\"bug\": timedelta(days=2)},\n            ),\n        ]\n        average_time_to_first_response = {\n            \"avg\": timedelta(days=2),\n            \"med\": timedelta(days=2),\n            \"90p\": timedelta(days=2),\n        }\n        average_time_to_close = {\n            \"avg\": timedelta(days=3),\n            \"med\": timedelta(days=3),\n            \"90p\": timedelta(days=3),\n        }\n        average_time_to_answer = {\n            \"avg\": timedelta(days=4),\n            \"med\": timedelta(days=4),\n            \"90p\": timedelta(days=4),\n        }\n        average_time_in_draft = {\n            \"avg\": timedelta(days=1),\n            \"med\": timedelta(days=1),\n            \"90p\": timedelta(days=1),\n        }\n        average_time_in_labels = {\n            \"avg\": {\"bug\": \"1 day, 12:00:00\"},\n            \"med\": {\"bug\": \"1 day, 12:00:00\"},\n            \"90p\": {\"bug\": \"1 day, 12:00:00\"},\n        }\n\n        num_issues_opened = 2\n        num_issues_closed = 1\n        num_mentor_count = 5\n\n        # Call the function\n        write_to_markdown(\n            issues_with_metrics=issues_with_metrics,\n            average_time_to_first_response=average_time_to_first_response,\n            average_time_to_close=average_time_to_close,\n            average_time_to_answer=average_time_to_answer,\n            average_time_in_draft=average_time_in_draft,\n            average_time_in_labels=average_time_in_labels,\n            num_issues_opened=num_issues_opened,\n            num_issues_closed=num_issues_closed,\n            num_mentor_count=num_mentor_count,\n            labels=[\"bug\"],\n            report_title=\"Issue Metrics\",\n            output_file=\"issue_metrics.md\",\n        )\n\n        # Check that the function writes the correct markdown file\n        with open(\"issue_metrics.md\", \"r\", encoding=\"utf-8\") as file:\n            content = file.read()\n        expected_content = (\n            \"# Issue Metrics\\n\\n\"\n            \"| Metric | Average | Median | 90th percentile |\\n\"\n            \"| --- | --- | --- | ---: |\\n\"\n            \"| Time to first response | 2 days, 0:00:00 | 2 days, 0:00:00 | 2 days, 0:00:00 |\\n\"\n            \"| Time to close | 3 days, 0:00:00 | 3 days, 0:00:00 | 3 days, 0:00:00 |\\n\"\n            \"| Time to answer | 4 days, 0:00:00 | 4 days, 0:00:00 | 4 days, 0:00:00 |\\n\"\n            \"| Time in draft | 1 day, 0:00:00 | 1 day, 0:00:00 | 1 day, 0:00:00 |\\n\"\n            \"| Time spent in bug | 1 day, 12:00:00 | 1 day, 12:00:00 | 1 day, 12:00:00 |\\n\"\n            \"\\n\"\n            \"| Metric | Count |\\n\"\n            \"| --- | ---: |\\n\"\n            \"| Number of items that remain open | 2 |\\n\"\n            \"| Number of items closed | 1 |\\n\"\n            \"| Number of most active mentors | 5 |\\n\"\n            \"| Total number of items created | 2 |\\n\\n\"\n            \"| Title | URL | Author | Time to first response | Time to close |\"\n            \" Time to answer | Time in draft | Time spent in bug | Created At |\\n\"\n            \"| --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n\"\n            \"| Issue 1 | https://github.com/user/repo/issues/1 | [alice](https://github.com/alice) | 1 day, 0:00:00 | \"\n            \"2 days, 0:00:00 | 3 days, 0:00:00 | 1 day, 0:00:00 | 1 day, 0:00:00 | -5 days, 0:00:00 |\\n\"\n            \"| feat&#124; Issue 2 | https://github.com/user/repo/issues/2 | [bob](https://github.com/bob) | 3 days, 0:00:00 | \"\n            \"4 days, 0:00:00 | 5 days, 0:00:00 | None | 2 days, 0:00:00 | -5 days, 0:00:00 |\\n\\n\"\n            \"_This report was generated with the [Issue Metrics Action](https://github.com/github/issue-metrics)_\\n\"\n        )\n        self.assertEqual(content, expected_content)\n        os.remove(\"issue_metrics.md\")\n\n    def test_write_to_markdown_no_issues(self):\n        \"\"\"Test that write_to_markdown writes the correct markdown file when no issues are found.\"\"\"\n        # Call the function with no issues\n        with patch(\"builtins.open\", mock_open()) as mock_open_file:\n            write_to_markdown(\n                None,\n                None,\n                None,\n                None,\n                None,\n                None,\n                None,\n                None,\n                None,\n                report_title=\"Issue Metrics\",\n            )\n\n        # Check that the file was written correctly\n        expected_output = [\n            \"# Issue Metrics\\n\\n\",\n            \"no issues found for the given search criteria\\n\\n\",\n            \"\\n_This report was generated with the [Issue Metrics Action](https://github.com/github/issue-metrics)_\\n\",\n        ]\n        # Check that the markdown file was written with the three calls in expected output\n        mock_open_file.assert_has_calls(\n            [\n                call().write(expected_output[0]),\n                call().write(expected_output[1]),\n                call().write(expected_output[2]),\n            ]\n        )\n\n\n@patch.dict(\n    os.environ,\n    {\n        \"SEARCH_QUERY\": \"is:open repo:user/repo\",\n        \"GH_TOKEN\": \"test_token\",\n        \"HIDE_CREATED_AT\": \"False\",\n        \"HIDE_TIME_TO_FIRST_RESPONSE\": \"True\",\n        \"HIDE_TIME_TO_CLOSE\": \"True\",\n        \"HIDE_TIME_TO_ANSWER\": \"True\",\n        \"HIDE_LABEL_METRICS\": \"True\",\n        \"NON_MENTIONING_LINKS\": \"True\",\n    },\n)\nclass TestWriteToMarkdownWithEnv(unittest.TestCase):\n    \"\"\"Test the write_to_markdown function with the HIDE* and NON_MENTIONING_LINKS environment variables set.\"\"\"\n\n    def test_writes_markdown_file_with_non_hidden_columns_only(self):\n        \"\"\"\n        Test that write_to_markdown writes the correct\n        markdown file with non-hidden columns only.\n        \"\"\"\n\n        # Create mock data\n        issues_with_metrics = [\n            IssueWithMetrics(\n                title=\"Issue 1\",\n                html_url=\"https://github.com/user/repo/issues/1\",\n                author=\"alice\",\n                created_at=timedelta(days=-5),\n                time_to_first_response=timedelta(minutes=10),\n                time_to_close=timedelta(days=1),\n                time_to_answer=timedelta(hours=2),\n                time_in_draft=timedelta(days=1),\n                labels_metrics={\n                    \"label1\": timedelta(days=1),\n                },\n            ),\n            IssueWithMetrics(\n                title=\"Issue 2\",\n                html_url=\"https://github.com/user/repo/issues/2\",\n                author=\"bob\",\n                created_at=timedelta(days=-5),\n                time_to_first_response=timedelta(minutes=20),\n                time_to_close=timedelta(days=2),\n                time_to_answer=timedelta(hours=4),\n                labels_metrics={\n                    \"label1\": timedelta(days=1),\n                },\n            ),\n        ]\n        average_time_to_first_response = timedelta(minutes=15)\n        average_time_to_close = timedelta(days1.5)\n        average_time_to_answer = timedelta(hours=3)\n        average_time_in_draft = timedelta(days=1)\n        average_time_in_labels = {\n            \"label1\": timedelta(days=1),\n        }\n        num_issues_opened = 2\n        num_issues_closed = 2\n        num_mentor_count = 5\n\n        # Call the function\n        write_to_markdown(\n            issues_with_metrics=issues_with_metrics,\n            average_time_to_first_response=average_time_to_first_response,\n            average_time_to_close=average_time_to_close,\n            average_time_to_answer=average_time_to_answer,\n            average_time_in_labels=average_time_in_labels,\n            average_time_in_draft=average_time_in_draft,\n            num_issues_opened=num_issues_opened,\n            num_issues_closed=num_issues_closed,\n            num_mentor_count=num_mentor_count,\n            labels=[\"label1\"],\n            search_query=\"repo:user/repo is:issue\",\n            hide_label_metrics=True,\n            hide_items_closed_count=True,\n            non_mentioning_links=True,\n            report_title=\"Issue Metrics\",\n            output_file=\"issue_metrics.md\",\n        )\n\n        # Check that the function writes the correct markdown file\n        with open(\"issue_metrics.md\", \"r\", encoding=\"utf-8\") as file:\n            content = file.read()\n\n        expected_content = (\n            \"# Issue Metrics\\n\\n\"\n            \"| Metric | Count |\\n\"\n            \"| --- | ---: |\\n\"\n            \"| Number of items that remain open | 2 |\\n\"\n            \"| Number of most active mentors | 5 |\\n\"\n            \"| Total number of items created | 2 |\\n\\n\"\n            \"| Title | URL | Author | Created At |\\n\"\n            \"| --- | --- | --- | --- |\\n\"\n            \"| Issue 1 | https://www.github.com/user/repo/issues/1 | [alice](https://github.com/alice) | -5 days, 0:00:00 |\\n\"\n            \"| Issue 2 | https://www.github.com/user/repo/issues/2 | [bob](https://github.com/bob) | -5 days, 0:00:00 |\\n\\n\"\n            \"_This report was generated with the [Issue Metrics Action](https://github.com/github/issue-metrics)_\\n\"\n            \"Search query used to find these items: `repo:user/repo is:issue`\\n\"\n        )\n        self.assertEqual(content, expected_content)\n        os.remove(\"issue_metrics.md\""
