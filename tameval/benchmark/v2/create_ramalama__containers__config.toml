[meta]
task = "create"
scenario = "extend_test_file"

[lang_info]
lang = "Python"
python_version = "3.13"
python_cfg_file = "pyproject.toml"

[repo_info]
repository = "containers/ramalama"
sha = "2c94e5f39c1f6c3253832353cbc2a225479b1dea"

[run_info]
docker_image = "python:3.13"
volumes_to_mount = [ "{proj_path}:/app", "{host}/.m2:/.m2", "{host}/.cache/pip:/.pip_cache", "{host}/.cache/go-build:/.go_cache", "{proj_path}/_HOME_/go:/go",]
docker_wrap = "sudo docker run --rm -w /app -e PATH=_HOME_/.local/bin:$PATH -e PYTHONUSERBASE=_HOME_/.local/ -v {proj_path}:/app -v {host}/.m2:/.m2 -v {host}/.cache/pip:/.pip_cache -v {host}/.cache/go-build:/.go_cache -v {proj_path}/_HOME_/go:/go {img} sh -c '{cmd}'"
env = [ "PATH=_HOME_/.local/bin:$PATH", "PYTHONUSERBASE=_HOME_/.local/",]
prebuild_command = "(pip install .[all,test] && pip install git+https://github.com/Klema17/mutpy.git && pip install coverage pytest pytest_cov covdefaults Cython mock ddt pytest_mock testfixtures)"
test_run_command = "coverage run --include=ramalama/config.py -m pytest -q --junit-xml=test_output.xml test/unit/test_config.py && coverage xml -o coverage.xml --fail-under=0"
mutation_run_command = "mut.py --target ramalama.config --unit-test test.unit.test_config --runner pytest --report mutation_report.yaml"
mutation_run_command_fallback = "mut.py --target ramalama/config.py --unit-test test/unit/test_config.py --runner pytest --report mutation_report.yaml"
coverage_report_path = "coverage.xml"
coverage_report_type = "cobertura"
mutation_report_path = "mutation_report.yaml"
mutation_report_type = "mutpy"

[coverage]
coverage = 91.0
original_coverage = 91.0
mutation_kill_rate = 100.0
original_mutation_kill_rate = 100.0
covered_lines = [ 0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 21, 23, 24, 26, 27, 29, 32, 33, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 55, 56, 59, 60, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 112, 119, 122, 123, 124, 126, 132, 133, 140, 141, 142, 145, 146, 150, 151, 154, 157, 158, 159, 161, 162, 163, 164, 166, 167, 169, 170, 171, 172, 173, 175, 177, 178, 180, 181, 183, 186, 187, 189, 190, 191, 193, 194, 195, 196, 199, 201, 204,]
missed_lines = [ 48, 127, 128, 129, 130, 143, 144, 147, 148, 149, 152, 153, 184,]

[input_info]
test_file_path = "test/unit/test_config.py"
focal_file_path = "ramalama/config.py"
test_file_url = "https://github.com/containers/ramalama/blob/2c94e5f39c1f6c3253832353cbc2a225479b1dea/test/unit/test_config.py"
focal_file_url = "https://github.com/containers/ramalama/blob/2c94e5f39c1f6c3253832353cbc2a225479b1dea/ramalama/config.py"
first_commit_date = "2025-02-26"
last_commit_date = "2025-08-13"
test_file_content = "import os\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom ramalama.config import DEFAULT_PORT, default_config, get_default_engine, get_default_store, load_env_config\n\n\ndef test_correct_config_defaults(monkeypatch):\n    monkeypatch.delenv(\"RAMALAMA_IMAGE\", raising=False)\n    cfg = default_config()\n\n    assert cfg.carimage == \"registry.access.redhat.com/ubi10-micro:latest\"\n    assert cfg.container in [True, False]  # depends on env/system\n    assert cfg.ctx_size == 2048\n    assert cfg.engine in [\"podman\", \"docker\", None]\n    assert cfg.env == []\n    assert cfg.host == \"0.0.0.0\"\n    assert cfg.image == cfg.default_image\n    assert isinstance(cfg.images, dict)\n    assert cfg.api == \"none\"\n    assert cfg.keep_groups is False\n    assert cfg.ngl == -1\n    assert cfg.threads == -1\n    assert cfg.port == str(DEFAULT_PORT)\n    assert cfg.pull == \"newer\"\n    assert cfg.runtime == \"llama.cpp\"\n    assert cfg.store == get_default_store()\n    assert cfg.temp == \"0.8\"\n    assert cfg.transport == \"ollama\"\n    assert cfg.ocr is False\n\n\ndef test_config_defaults_not_set(monkeypatch):\n    monkeypatch.delenv(\"RAMALAMA_IMAGE\", raising=False)\n    cfg = default_config()\n\n    assert cfg.is_set(\"carimage\") is False\n    assert cfg.is_set(\"container\") is False  # depends on env/system\n    assert cfg.is_set(\"ctx_size\") is False\n    assert cfg.is_set(\"engine\") is False\n    assert cfg.is_set(\"env\") is False\n    assert cfg.is_set(\"host\") is False\n    assert cfg.is_set(\"image\") is False\n    assert cfg.is_set(\"images\") is False\n    assert cfg.is_set(\"api\") is False\n    assert cfg.is_set(\"keep_groups\") is False\n    assert cfg.is_set(\"ngl\") is False\n    assert cfg.is_set(\"threads\") is False\n    assert cfg.is_set(\"port\") is False\n    assert cfg.is_set(\"pull\") is False\n    assert cfg.is_set(\"runtime\") is False\n    assert cfg.is_set(\"store\") is False\n    assert cfg.is_set(\"temp\") is False\n    assert cfg.is_set(\"transport\") is False\n    assert cfg.is_set(\"ocr\") is False\n\n\ndef test_file_config_overrides_defaults():\n    mock_file_config = {\n        \"image\": \"custom/image:latest\",\n        \"threads\": 8,\n        \"container\": False,\n    }\n\n    with patch(\"ramalama.config.load_file_config\", return_value=mock_file_config):\n        with patch(\"ramalama.config.load_env_config\", return_value={}):\n            cfg = default_config()\n            assert cfg.image == \"custom/image:latest\"\n            assert cfg.threads == 8\n            assert cfg.container is False\n\n            assert cfg.is_set(\"image\") is True\n            assert cfg.is_set(\"threads\") is True\n            assert cfg.is_set(\"container\") is True\n\n\ndef test_env_overrides_file_and_default():\n    mock_file_config = {\n        \"image\": \"custom/image:latest\",\n        \"threads\": 8,\n    }\n    mock_env_config = {\n        \"image\": \"env/image:override\",\n        \"threads\": 16,\n    }\n\n    with patch(\"ramalama.config.load_file_config\", return_value=mock_file_config):\n        with patch(\"ramalama.config.load_env_config\", return_value=mock_env_config):\n            cfg = default_config()\n            assert cfg.image == \"env/image:override\"\n            assert cfg.threads == 16\n\n            assert cfg.is_set(\"image\") is True\n            assert cfg.is_set(\"threads\") is True\n\n\n@pytest.mark.parametrize(\n    \"uid,is_root,expected\",\n    [\n        (0, True, \"/var/lib/ramalama\"),\n        (1000, False, os.path.expanduser(\"~/.local/share/ramalama\")),\n    ],\n)\ndef test_get_default_store(uid, is_root, expected):\n    with patch(\"os.geteuid\", return_value=uid):\n        assert get_default_store() == expected\n\n\n@pytest.mark.parametrize(\n    \"env_value,expected\",\n    [\n        (\"true\", True),\n        (\"false\", False),\n        (\"True\", True),\n        (\"False\", False),\n    ],\n)\ndef test_cfg_container_env_override(env_value, expected):\n    with patch.dict(os.environ, {\"RAMALAMA_IN_CONTAINER\": env_value} if env_value is not None else {}, clear=True):\n        cfg = default_config()\n        assert cfg.is_set(\"container\") is True\n        print(os.environ)\n        assert cfg.container == expected, cfg.container\n\n\ndef test_cfg_container_not_set():\n    with patch.dict(os.environ, {\"RAMALAMA_CONTAINER_ENGINE\": \"podman\"}):\n        cfg = default_config()\n        assert cfg.is_set(\"container\") is False\n        assert cfg.container is True\n\n    with patch.dict(os.environ, {}):\n        cfg = default_config()\n        with patch(\"ramalama.config.load_env_config\", return_value={}):\n            assert cfg.is_set(\"container\") is False\n            assert cfg.container is (cfg.engine is not None)\n\n\nclass TestGetDefaultEngine:\n\n    def test_get_default_engine_with_toolboxenv(self):\n        with patch(\"os.getenv\", return_value=None):\n            with patch(\"os.path.exists\", side_effect=lambda x: x == \"/run/.toolboxenv\"):\n                assert get_default_engine() is None\n\n    @pytest.mark.parametrize(\n        \"platform,expected\",\n        [\n            (\"darwin\", \"podman\"),\n            (\"linux\", \"podman\"),\n        ],\n    )\n    def test_get_default_engine_with_podman_available(self, platform, expected):\n        with patch(\"ramalama.config.available\", side_effect=lambda x: x == \"podman\"):\n            with patch(\"sys.platform\", platform):\n                assert get_default_engine() == expected\n\n    def test_get_default_engine_with_podman_available_osx_apple_vm_has_podman(self):\n        with patch(\"ramalama.config.available\", side_effect=lambda x: x == \"podman\"):\n            with patch(\"sys.platform\", \"darwin\"):\n                assert get_default_engine() == \"podman\"\n\n    def test_get_default_engine_with_docker_available_osx(self):\n        with patch(\"ramalama.config.available\", side_effect=lambda x: x == \"docker\"):\n            with patch(\"sys.platform\", \"darwin\"):\n                assert get_default_engine() is None\n\n    def test_get_default_engine_with_docker_available_linux(self):\n        with patch(\"ramalama.config.available\", side_effect=lambda x: x == \"docker\"):\n            with patch(\"sys.platform\", \"linux\"):\n                assert get_default_engine() == \"docker\"\n\n\nclass TestLoadEnvConfig:\n    \"\"\"Test the load_env_config function for arbitrary environment variable loading.\"\"\"\n\n    def test_load_env_config_basic_variables(self):\n        \"\"\"Test loading basic RAMALAMA environment variables.\"\"\"\n        env = {\n            \"RAMALAMA_IMAGE\": \"test/image:latest\",\n            \"RAMALAMA_THREADS\": \"8\",\n            \"RAMALAMA_CONTAINER\": \"true\",\n            \"RAMALAMA_HOST\": \"127.0.0.1\",\n        }\n\n        result = load_env_config(env)\n\n        expected = {\n            \"image\": \"test/image:latest\",\n            \"threads\": 8,\n            \"container\": True,\n            \"host\": \"127.0.0.1\",\n        }\n        assert result == expected\n\n    def test_load_env_config_nested_variables(self):\n        \"\"\"Test loading nested configuration via double underscores.\"\"\"\n        env = {\n            \"RAMALAMA_USER__NO_MISSING_GPU_PROMPT\": \"true\",\n            \"RAMALAMA_SETTINGS__CONFIG_FILES\": [\"/path/to/config\"],\n            \"RAMALAMA_IMAGES\": '{\"CUDA_VISIBLE_DEVICES\": \"custom/cuda:latest\"}',\n        }\n\n        result = load_env_config(env)\n\n        expected = {\n            \"user\": {\"no_missing_gpu_prompt\": \"true\"},\n            \"settings\": {\"config_files\": [\"/path/to/config\"]},\n            \"images\": {\"CUDA_VISIBLE_DEVICES\": \"custom/cuda:latest\"},\n        }\n\n        assert result == expected\n\n    def test_load_env_config_deeply_nested_variables(self):\n        \"\"\"Test loading deeply nested configuration.\"\"\"\n        env = {\n            \"RAMALAMA_DATABASE__CONNECTION__HOST\": \"localhost\",\n            \"RAMALAMA_DATABASE__CONNECTION__PORT\": \"5432\",\n            \"RAMALAMA_DATABASE__CREDENTIALS__USERNAME\": \"user\",\n            \"RAMALAMA_DATABASE__CREDENTIALS__PASSWORD\": \"pass\",\n        }\n\n        result = load_env_config(env)\n\n        expected = {\n            \"database\": {\n                \"connection\": {\"host\": \"localhost\", \"port\": \"5432\"},\n                \"credentials\": {\"username\": \"user\", \"password\": \"pass\"},\n            }\n        }\n        assert result == expected\n\n    def test_load_env_config_legacy_variables(self):\n        \"\"\"Test loading legacy environment variables.\"\"\"\n        env = {\n            \"RAMALAMA_IN_CONTAINER\": \"true\",\n            \"RAMALAMA_CONTAINER_ENGINE\": \"docker\",\n        }\n\n        result = load_env_config(env)\n\n        expected = {\n            \"container\": True,\n            \"engine\": \"docker\",\n        }\n        assert result == expected\n\n    def test_load_env_config_mixed_legacy_and_new(self):\n        \"\"\"Test loading both legacy and new environment variables.\"\"\"\n        env = {\n            \"RAMALAMA_IN_CONTAINER\": \"true\",\n            \"RAMALAMA_CONTAINER_ENGINE\": \"docker\",\n            \"RAMALAMA_IMAGE\": \"test/image:latest\",\n            \"RAMALAMA_USER__NO_MISSING_GPU_PROMPT\": \"true\",\n        }\n\n        result = load_env_config(env)\n\n        expected = {\n            \"container\": True,\n            \"engine\": \"docker\",\n            \"image\": \"test/image:latest\",\n            \"user\": {\"no_missing_gpu_prompt\": \"true\"},\n        }\n        assert result == expected\n\n    def test_load_env_config_ignores_non_ramalama_vars(self):\n        \"\"\"Test that non-RAMALAMA environment variables are ignored.\"\"\"\n        env = {\n            \"RAMALAMA_IMAGE\": \"test/image:latest\",\n            \"PATH\": \"/usr/bin:/bin\",\n            \"HOME\": \"/home/user\",\n            \"RAMALAMA_THREADS\": \"8\",\n            \"SHELL\": \"/bin/bash\",\n        }\n\n        result = load_env_config(env)\n\n        expected = {\n            \"image\": \"test/image:latest\",\n            \"threads\": 8,\n        }\n        assert result == expected\n\n    def test_load_env_config_empty_environment(self):\n        \"\"\"Test loading from empty environment.\"\"\"\n        result = load_env_config({})\n        assert result == {}\n\n    def test_load_env_config_none_environment(self):\n        \"\"\"Test loading with None environment (should use os.environ).\"\"\"\n        with patch(\"os.environ\", {\"RAMALAMA_IMAGE\": \"test/image:latest\"}):\n            result = load_env_config()\n            assert result == {\"image\": \"test/image:latest\"}\n\n    def test_load_env_config_case_insensitive_keys(self):\n        \"\"\"Test that keys are converted to lowercase.\"\"\"\n        env = {\n            \"RAMALAMA_IMAGE\": \"test/image:latest\",\n            \"RAMALAMA_THREADS\": \"8\",\n            \"RAMALAMA_USER__NO_MISSING_GPU_PROMPT\": \"true\",\n        }\n\n        result = load_env_config(env)\n\n        # All keys should be lowercase\n        assert \"image\" in result\n        assert \"threads\" in result\n        assert \"user\" in result\n        assert \"no_missing_gpu_prompt\" in result[\"user\"]\n\n    def test_load_env_config_single_underscore_prefix(self):\n        \"\"\"Test handling of single underscore prefix.\"\"\"\n        env = {\n            \"RAMALAMA_IMAGE\": \"test/image:latest\",\n            \"RAMALAMA__NESTED__VALUE\": \"nested_value\",\n        }\n\n        result = load_env_config(env)\n\n        expected = {\"image\": \"test/image:latest\", \"nested\": {\"value\": \"nested_value\"}}\n        assert result == expected\n\n    def test_load_env_config_double_underscore_prefix(self):\n        \"\"\"Test handling of double underscore prefix.\"\"\"\n        env = {\n            \"RAMALAMA__DEEP__NESTED__VALUE\": \"deep_value\",\n        }\n\n        result = load_env_config(env)\n\n        expected = {\"deep\": {\"nested\": {\"value\": \"deep_value\"}}}\n        assert result == expected\n\n    def test_load_env_config_mixed_underscore_prefixes(self):\n        \"\"\"Test handling of mixed underscore prefixes.\"\"\"\n        env = {\n            \"RAMALAMA_IMAGE\": \"test/image:latest\",\n            \"RAMALAMA__NESTED__VALUE\": \"nested_value\",\n            \"RAMALAMA___TRIPLE___VALUE\": \"triple_value\",\n        }\n\n        result = load_env_config(env)\n\n        expected = {\n            \"image\": \"test/image:latest\",\n            \"nested\": {\"value\": \"nested_value\"},\n            \"triple\": {\"_value\": \"triple_value\"},\n        }\n        assert result == expected\n\n    def test_load_env_config_empty_subkeys(self):\n        \"\"\"Test handling of empty subkeys.\"\"\"\n        env = {\n            \"RAMALAMA__\": \"empty_prefix\",\n            \"RAMALAMA___\": \"triple_underscore\",\n        }\n\n        result = load_env_config(env)\n\n        expected = {\n            \"\": \"triple_underscore\",  # This will overwrite the previous one\n        }\n        assert result == expected\n\n    def test_load_env_config_special_characters(self):\n        \"\"\"Test handling of special characters in values.\"\"\"\n        env = {\n            \"RAMALAMA_STRING_VALUE\": \"test with spaces\",\n            \"RAMALAMA_NUMBER_VALUE\": \"123\",\n            \"RAMALAMA_BOOL_VALUE\": \"true\",\n            \"RAMALAMA_SPECIAL_VALUE\": \"test@example.com\",\n        }\n\n        result = load_env_config(env)\n\n        expected = {\n            \"string_value\": \"test with spaces\",\n            \"number_value\": \"123\",\n            \"bool_value\": \"true\",\n            \"special_value\": \"test@example.com\",\n        }\n        assert result == expected\n\n    def test_load_env_config_complex_nesting(self):\n        \"\"\"Test complex nesting scenarios.\"\"\"\n        env = {\n            \"RAMALAMA_APP__DATABASE__HOST\": \"localhost\",\n            \"RAMALAMA_APP__DATABASE__PORT\": \"5432\",\n            \"RAMALAMA_APP__LOGGING__LEVEL\": \"debug\",\n            \"RAMALAMA_APP__LOGGING__FILE\": \"/var/log/app.log\",\n            \"RAMALAMA_APP__FEATURES__ENABLED\": \"true\",\n            \"RAMALAMA_APP__FEATURES__MAX_CONNECTIONS\": \"100\",\n        }\n\n        result = load_env_config(env)\n\n        expected = {\n            \"app\": {\n                \"database\": {\"host\": \"localhost\", \"port\": \"5432\"},\n                \"logging\": {\"level\": \"debug\", \"file\": \"/var/log/app.log\"},\n                \"features\": {\"enabled\": \"true\", \"max_connections\": \"100\"},\n            }\n        }\n        assert result == expected\n\n    def test_debug_images_loading(self):\n        \"\"\"Debug test to see what load_env_config returns for images.\"\"\"\n        env = {\n            \"RAMALAMA_IMAGES\": (\n                '{\"CUDA_VISIBLE_DEVICES\": \"custom/cuda:latest\", \"INTEL_VISIBLE_DEVICES\": \"custom/intel:latest\"}'\n            ),\n        }\n\n        result = load_env_config(env)\n        print(f\"load_env_config result: {result}\")\n\n        # Should contain the parsed images dict\n        assert \"images\" in result\n        assert result[\"images\"] == {\n            \"CUDA_VISIBLE_DEVICES\": \"custom/cuda:latest\",\n            \"INTEL_VISIBLE_DEVICES\": \"custom/intel:latest\",\n        }\n\n    def test_stack_image(self):\n        \"\"\"Test that the llama-stack image can be set from an env var.\"\"\"\n        env = {\n            \"RAMALAMA_STACK_IMAGE\": \"custom/llama-stack:latest\",\n        }\n        result = load_env_config(env)\n        assert \"stack_image\" in result\n        assert result[\"stack_image\"] == \"custom/llama-stack:latest\"\n\n\nclass TestConfigIntegration:\n    \"\"\"Integration tests for the complete config system with deep merge and env loading.\"\"\"\n\n    def test_config_with_nested_env_variables(self):\n        \"\"\"Test that nested environment variables are properly loaded and merged.\"\"\"\n        env = {\n            \"RAMALAMA_USER__NO_MISSING_GPU_PROMPT\": \"true\",\n            \"RAMALAMA_SETTINGS__CONFIG_FILES\": [\"/custom/config.toml\"],\n            \"RAMALAMA_IMAGES\": (\n                '{\"CUDA_VISIBLE_DEVICES\": \"custom/cuda:latest\", \"HIP_VISIBLE_DEVICES\": \"custom/rocm:latest\"}'\n            ),\n        }\n\n        with patch(\"ramalama.config.load_file_config\", return_value={}):\n            cfg = default_config(env)\n\n            assert cfg.user.no_missing_gpu_prompt is True\n            assert cfg.settings.config_files == [\"/custom/config.toml\"]\n            assert cfg.images[\"CUDA_VISIBLE_DEVICES\"] == \"custom/cuda:latest\"\n            assert cfg.images[\"HIP_VISIBLE_DEVICES\"] == \"custom/rocm:latest\"\n\n            assert cfg.is_set(\"user\") is True\n            assert cfg.is_set(\"settings\") is True\n            assert cfg.is_set(\"images\") is True\n\n    def test_config_env_overrides_file_config(self):\n        \"\"\"Test that environment variables override file config.\"\"\"\n        file_config = {\n            \"image\": \"file/image:latest\",\n            \"threads\": 4,\n            \"user\": {\"no_missing_gpu_prompt\": False},\n            \"images\": {\"CUDA_VISIBLE_DEVICES\": \"file/cuda:latest\"},\n        }\n\n        env = {\n            \"RAMALAMA_IMAGE\": \"env/image:latest\",\n            \"RAMALAMA_THREADS\": \"8\",\n            \"RAMALAMA_USER__NO_MISSING_GPU_PROMPT\": \"true\",\n            \"RAMALAMA_IMAGES\": '{\"CUDA_VISIBLE_DEVICES\": \"env/cuda:latest\"}',\n        }\n\n        with patch(\"ramalama.config.load_file_config\", return_value=file_config):\n            cfg = default_config(env)\n\n            # Environment should override file config\n            assert cfg.image == \"env/image:latest\"\n            assert cfg.threads == 8\n            assert cfg.user.no_missing_gpu_prompt is True\n            assert cfg.images[\"CUDA_VISIBLE_DEVICES\"] == \"env/cuda:latest\"\n\n    def test_config_multiple_env_layers(self):\n        \"\"\"Test that multiple environment variable layers work correctly.\"\"\"\n        env = {\n            \"RAMALAMA_IMAGE\": \"base/image:latest\",\n            \"RAMALAMA_THREADS\": \"4\",\n            \"RAMALAMA_USER__NO_MISSING_GPU_PROMPT\": \"false\",\n            \"RAMALAMA_IMAGES\": '{\"CUDA_VISIBLE_DEVICES\": \"base/cuda:latest\"}',\n            \"RAMALAMA_APP__DATABASE__HOST\": \"localhost\",\n            \"RAMALAMA_APP__DATABASE__PORT\": \"5432\",\n        }\n\n        with patch(\"ramalama.config.load_file_config\", return_value={}):\n            cfg = default_config(env)\n\n            # Basic config should work\n            assert cfg.image == \"base/image:latest\"\n            assert cfg.threads == 4\n            assert cfg.user.no_missing_gpu_prompt is False\n            assert cfg.images[\"CUDA_VISIBLE_DEVICES\"] == \"base/cuda:latest\"\n\n            # Arbitrary nested config should be available\n            # Note: This would require the config to support arbitrary fields\n            # For now, we just verify the basic functionality works\n\n    def test_config_legacy_compatibility(self):\n        \"\"\"Test that legacy environment variables still work.\"\"\"\n        env = {\n            \"RAMALAMA_IN_CONTAINER\": \"true\",\n            \"RAMALAMA_CONTAINER_ENGINE\": \"docker\",\n            \"RAMALAMA_IMAGE\": \"test/image:latest\",\n        }\n\n        with patch(\"ramalama.config.load_file_config\", return_value={}):\n            cfg = default_config(env)\n\n            assert cfg.container is True\n            assert cfg.engine == \"docker\"\n            assert cfg.image == \"test/image:latest\"\n\n    def test_config_empty_layers(self):\n        \"\"\"Test behaviour with empty configuration layers.\"\"\"\n        with patch(\"ramalama.config.load_file_config\", return_value={}):\n            cfg = default_config({})\n\n            # Should use defaults\n            assert cfg.image == cfg.default_image\n            assert cfg.threads == -1\n            assert cfg.user.no_missing_gpu_prompt is False\n\n    def test_config_type_coercion(self):\n        \"\"\"Test that environment variables are properly type-coerced.\"\"\"\n        env = {\n            \"RAMALAMA_THREADS\": \"16\",\n            \"RAMALAMA_CTX_SIZE\": \"4096\",\n            \"RAMALAMA_NGL\": \"2\",\n            \"RAMALAMA_CONTAINER\": \"true\",\n            \"RAMALAMA_KEEP_GROUPS\": \"true\",\n            \"RAMALAMA_OCR\": \"true\",\n            \"RAMALAMA_USER__NO_MISSING_GPU_PROMPT\": \"true\",\n        }\n\n        with patch(\"ramalama.config.load_file_config\", return_value={}):\n            cfg = default_config(env)\n\n            assert cfg.threads == 16\n            assert cfg.ctx_size == 4096\n            assert cfg.ngl == 2\n            assert cfg.container is True\n            assert cfg.keep_groups is True\n            assert cfg.ocr is True\n            assert cfg.user.no_missing_gpu_prompt is True\n\n    def test_config_complex_nesting_scenario(self):\n        \"\"\"Test a complex real-world nesting scenario.\"\"\"\n        file_config = {\n            \"images\": {\n                \"CUDA_VISIBLE_DEVICES\": \"quay.io/ramalama/cuda:latest\",\n                \"HIP_VISIBLE_DEVICES\": \"quay.io/ramalama/rocm:latest\",\n            },\n            \"user\": {\"no_missing_gpu_prompt\": False},\n        }\n\n        env = {\n            \"RAMALAMA_IMAGE\": \"custom/ramalama:latest\",\n            \"RAMALAMA_THREADS\": \"8\",\n            \"RAMALAMA_IMAGES\": (\n                '{\"CUDA_VISIBLE_DEVICES\": \"custom/cuda:latest\", \"INTEL_VISIBLE_DEVICES\": \"custom/intel:latest\"}'\n            ),\n            \"RAMALAMA_USER__NO_MISSING_GPU_PROMPT\": \"true\",\n            \"RAMALAMA_APP__LOGGING__LEVEL\": \"debug\",\n            \"RAMALAMA_APP__LOGGING__FILE\": \"/var/log/ramalama.log\",\n        }\n\n        with patch(\"ramalama.config.load_file_config\", return_value=file_config):\n            cfg = default_config(env)\n\n            # Verify the merged configuration\n            assert cfg.image == \"custom/ramalama:latest\"\n            assert cfg.threads == 8\n            assert cfg.user.no_missing_gpu_prompt is True\n\n            # Deep merged images\n            expected_images = {\n                \"CUDA_VISIBLE_DEVICES\": \"custom/cuda:latest\",  # from env\n                \"INTEL_VISIBLE_DEVICES\": \"custom/intel:latest\",  # from env\n                \"HIP_VISIBLE_DEVICES\": \"quay.io/ramalama/rocm:latest\",  # from file config\n            }\n            assert cfg.images == expected_images\n\n    def test_config_is_set_behavior(self):\n        \"\"\"Test that is_set correctly tracks configuration sources.\"\"\"\n        file_config = {\n            \"image\": \"file/image:latest\",\n            \"threads\": 4,\n        }\n\n        env = {\n            \"RAMALAMA_IMAGE\": \"env/image:latest\",\n            \"RAMALAMA_USER__NO_MISSING_GPU_PROMPT\": \"true\",\n        }\n\n        with patch(\"ramalama.config.load_file_config\", return_value=file_config):\n            cfg = default_config(env)\n\n            # Values set in either layer should return True\n            assert cfg.is_set(\"image\") is True\n            assert cfg.is_set(\"threads\") is True\n            assert cfg.is_set(\"user\") is True\n\n            # Values not set in any layer should return False\n            assert cfg.is_set(\"host\") is False\n            assert cfg.is_set(\"port\") is False\n"
