[meta]
task = "create"
scenario = "extend_test_file"

[lang_info]
lang = "Python"
python_version = "3.13"
python_cfg_file = "pyproject.toml"

[repo_info]
repository = "megvii-research/megfile"
sha = "0dd2329354b37b41cb8ec31cfd5c15c5e0b1af35"

[run_info]
docker_image = "python:3.13"
volumes_to_mount = [ "{proj_path}:/app", "{host}/.m2:/.m2", "{host}/.cache/pip:/.pip_cache", "{host}/.cache/go-build:/.go_cache", "{proj_path}/_HOME_/go:/go",]
docker_wrap = "sudo docker run --rm -w /app -e PATH=_HOME_/.local/bin:$PATH -e PYTHONUSERBASE=_HOME_/.local/ -v {proj_path}:/app -v {host}/.m2:/.m2 -v {host}/.cache/pip:/.pip_cache -v {host}/.cache/go-build:/.go_cache -v {proj_path}/_HOME_/go:/go {img} sh -c '{cmd}'"
env = [ "PATH=_HOME_/.local/bin:$PATH", "PYTHONUSERBASE=_HOME_/.local/",]
prebuild_command = "pip install -r requirements.txt && pip install -r requirements-cli.txt && pip install -r requirements-hdfs.txt && pip install -r requirements-dev.txt && (pip install .[all,test] && pip install git+https://github.com/Klema17/mutpy.git && pip install coverage pytest pytest_cov covdefaults Cython mock ddt pytest_mock testfixtures)"
test_run_command = "coverage run --include=megfile/errors.py -m pytest -q --junit-xml=test_output.xml tests/test_errors.py && coverage xml -o coverage.xml --fail-under=0"
mutation_run_command = "mut.py --target megfile.errors --unit-test tests.test_errors --runner pytest --report mutation_report.yaml"
mutation_run_command_fallback = "mut.py --target megfile/errors.py --unit-test tests/test_errors.py --runner pytest --report mutation_report.yaml"
coverage_report_path = "coverage.xml"
coverage_report_type = "cobertura"
mutation_report_path = "mutation_report.yaml"
mutation_report_type = "mutpy"

[coverage]
coverage = 84.0
original_coverage = 84.0
mutation_kill_rate = 100.0
original_mutation_kill_rate = 100.0
covered_lines = [ 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 15, 16, 18, 20, 48, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 72, 73, 74, 76, 79, 80, 83, 84, 85, 88, 89, 92, 93, 96, 111, 112, 115, 117, 145, 146, 147, 148, 149, 150, 153, 161, 162, 163, 166, 167, 168, 169, 171, 172, 173, 174, 175, 177, 179, 180, 184, 185, 186, 190, 192, 195, 211, 212, 213, 217, 218, 219, 220, 221, 222, 224, 225, 228, 229, 230, 231, 232, 234, 235, 238, 245, 246, 249, 250, 253, 254, 257, 258, 261, 262, 265, 266, 269, 270, 273, 280, 281, 284, 285, 288, 289, 292, 293, 294, 297, 304, 305, 308, 309, 312, 313, 316, 317, 320, 333, 334, 335, 336, 339, 340, 343, 344, 347, 348, 349, 350, 351, 355, 359, 360, 361, 362, 363, 364, 370, 374, 375, 376, 377, 378, 382, 383, 384, 388, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 416, 417, 418, 419, 420, 421, 424, 434, 435, 436, 437, 438, 439, 440, 441, 442, 445, 446, 456, 462, 463, 466, 467, 468, 469, 470, 481, 482,]
missed_lines = [ 164, 170, 176, 178, 196, 197, 199, 200, 201, 202, 204, 205, 206, 208, 352, 389, 447, 448, 449, 450, 451, 452, 453, 457, 458, 459, 471, 472, 473, 474, 475, 476, 478, 483, 484, 485, 486,]

[input_info]
test_file_path = "tests/test_errors.py"
focal_file_path = "megfile/errors.py"
test_file_url = "https://github.com/megvii-research/megfile/blob/0dd2329354b37b41cb8ec31cfd5c15c5e0b1af35/tests/test_errors.py"
focal_file_url = "https://github.com/megvii-research/megfile/blob/0dd2329354b37b41cb8ec31cfd5c15c5e0b1af35/megfile/errors.py"
first_commit_date = "2021-08-23"
last_commit_date = "2025-07-29"
test_file_content = "import logging\nimport pickle\n\nimport boto3.exceptions\nimport botocore.exceptions\nimport pytest\nimport urllib3.exceptions\n\nfrom megfile.errors import (\n    ClientError,\n    HTTPError,\n    HttpException,\n    HttpFileNotFoundError,\n    HttpPermissionError,\n    HttpUnknownError,\n    NoCredentialsError,\n    ParamValidationError,\n    S3BucketNotFoundError,\n    S3ConfigError,\n    S3Exception,\n    S3FileNotFoundError,\n    S3InvalidRangeError,\n    S3PermissionError,\n    S3UnknownError,\n    UnknownError,\n    UnsupportedError,\n    http_retry_exceptions,\n    http_should_retry,\n    patch_method,\n    s3_endpoint_url,\n    s3_retry_exceptions,\n    s3_should_retry,\n    translate_fs_error,\n    translate_hdfs_error,\n    translate_http_error,\n    translate_s3_error,\n)\n\n\ndef test_megfile_unknown_error():\n    cause = Exception(\"cause\")\n    error = UnknownError(cause, \"path\")\n    assert \"Exception(\" in str(error)\n    assert \"cause\" in str(error)\n    assert \"path\" in str(error)\n    assert error.__cause__ is cause\n\n\ndef test_megfile_unknown_error_pickle():\n    cause = Exception(\"cause\")\n    error = UnknownError(cause, \"path\")\n    error = pickle.loads(pickle.dumps(error))\n    assert \"Exception(\" in str(error)\n    assert \"cause\" in str(error)\n    assert \"path\" in str(error)\n    assert str(error.__cause__) == str(cause)\n\n\ndef test_megfile_unsupported_error_pickle():\n    error = UnsupportedError(\"operation\", \"path\")\n    error = pickle.loads(pickle.dumps(error))\n    assert \"path\" in str(error)\n\n\ndef test_translate_s3_error():\n    s3_url = \"s3://test\"\n\n    s3_error = S3Exception()\n    assert isinstance(translate_s3_error(s3_error, s3_url), S3Exception)\n\n    error_response = {\"Error\": {\"Code\": \"NoSuchBucket\"}}\n    client_error = ClientError(error_response, operation_name=\"test\")\n    assert isinstance(translate_s3_error(client_error, s3_url), S3BucketNotFoundError)\n\n    error_response = {\"Error\": {\"Code\": \"404\"}}\n    client_error = ClientError(error_response, operation_name=\"test\")\n    assert isinstance(translate_s3_error(client_error, s3_url), S3FileNotFoundError)\n\n    error_response = {\"Error\": {\"Code\": \"401\"}}\n    client_error = ClientError(error_response, operation_name=\"test\")\n    assert isinstance(translate_s3_error(client_error, s3_url), S3PermissionError)\n\n    error_response = {\"Error\": {\"Code\": \"InvalidAccessKeyId\"}}\n    client_error = ClientError(error_response, operation_name=\"test\")\n    assert isinstance(translate_s3_error(client_error, s3_url), S3ConfigError)\n\n    error_response = {\"Error\": {\"Code\": \"unKnow\"}}\n    client_error = ClientError(error_response, operation_name=\"test\")\n    assert isinstance(translate_s3_error(client_error, s3_url), S3UnknownError)\n\n    param_validation_error = ParamValidationError(report=\"Invalid bucket name\")\n    assert isinstance(\n        translate_s3_error(param_validation_error, s3_url), S3BucketNotFoundError\n    )\n\n    param_validation_error = ParamValidationError(\n        report=\"Invalid length for parameter Key\"\n    )\n    assert isinstance(\n        translate_s3_error(param_validation_error, s3_url), S3FileNotFoundError\n    )\n\n    param_validation_error = ParamValidationError(report=\"unKnow\")\n    assert isinstance(\n        translate_s3_error(param_validation_error, s3_url), S3UnknownError\n    )\n\n    no_credentials_error = NoCredentialsError()\n    assert isinstance(translate_s3_error(no_credentials_error, s3_url), S3ConfigError)\n\n    exception_error = Exception()\n    assert isinstance(translate_s3_error(exception_error, s3_url), S3UnknownError)\n\n    s3_upload_failed_error = boto3.exceptions.S3UploadFailedError(\"NoSuchBucket\")\n    assert isinstance(\n        translate_s3_error(s3_upload_failed_error, s3_url), S3BucketNotFoundError\n    )\n\n    s3_transfer_failed_error = boto3.exceptions.S3TransferFailedError(\"NoSuchKey\")\n    assert isinstance(\n        translate_s3_error(s3_transfer_failed_error, s3_url), S3FileNotFoundError\n    )\n\n    s3_upload_failed_error = boto3.exceptions.S3UploadFailedError(\"InvalidAccessKeyId\")\n    assert isinstance(translate_s3_error(s3_upload_failed_error, s3_url), S3ConfigError)\n\n    s3_upload_failed_error = boto3.exceptions.S3UploadFailedError(\"InvalidRange\")\n    assert isinstance(\n        translate_s3_error(s3_upload_failed_error, s3_url), S3InvalidRangeError\n    )\n\n    s3_upload_failed_error = boto3.exceptions.S3UploadFailedError(\"AccessDenied\")\n    assert isinstance(\n        translate_s3_error(s3_upload_failed_error, s3_url), S3PermissionError\n    )\n\n\ndef test_translate_http_error():\n    url = \"http://test.com\"\n\n    http_exception = HttpException()\n    assert isinstance(translate_http_error(http_exception, http_url=url), HttpException)\n\n    class FakeResponse:\n        def __init__(self, status_code) -> None:\n            self.status_code = status_code\n            pass\n\n    http_error = HTTPError(response=FakeResponse(401))\n    assert isinstance(\n        translate_http_error(http_error, http_url=url), HttpPermissionError\n    )\n\n    http_error = HTTPError(response=FakeResponse(404))\n    assert isinstance(\n        translate_http_error(http_error, http_url=url), HttpFileNotFoundError\n    )\n\n    http_error = HTTPError(response=FakeResponse(500))\n    assert isinstance(translate_http_error(http_error, http_url=url), HttpUnknownError)\n\n\ndef test_translate_fs_error():\n    error = OSError(1, \"test\", None, None)\n    fs_path = \"/test\"\n    translate_error = translate_fs_error(error, fs_path=fs_path)\n    assert translate_error.filename == fs_path\n\n\ndef test_http_should_retry():\n    for Error in http_retry_exceptions:\n        if Error is urllib3.exceptions.IncompleteRead:\n            assert http_should_retry(Error(partial=\"test\", expected=\"test\")) is True\n        elif Error is urllib3.exceptions.ReadTimeoutError:\n            assert (\n                http_should_retry(Error(pool=1, url=\"http:test\", message=\"test\"))\n                is True\n            )\n        else:\n            assert http_should_retry(Error()) is True\n    error = Exception()\n    assert http_should_retry(error) is False\n\n\ndef test_s3_should_retry():\n    for Error in s3_retry_exceptions:\n        if Error is urllib3.exceptions.IncompleteRead:\n            assert s3_should_retry(Error(partial=\"test\", expected=\"test\")) is True\n        elif Error is urllib3.exceptions.ReadTimeoutError:\n            assert (\n                s3_should_retry(Error(pool=1, url=\"http:test\", message=\"test\")) is True\n            )\n        elif Error is botocore.exceptions.IncompleteReadError:\n            assert (\n                s3_should_retry(Error(actual_bytes=b\"test\", expected_bytes=b\"test\"))\n                is True\n            )\n        elif Error is botocore.exceptions.EndpointConnectionError:\n            assert s3_should_retry(Error(endpoint_url=\"test\")) is True\n        elif Error is botocore.exceptions.ReadTimeoutError:\n            assert s3_should_retry(Error(endpoint_url=\"test\")) is True\n        elif Error is botocore.exceptions.ConnectTimeoutError:\n            assert s3_should_retry(Error(endpoint_url=\"test\")) is True\n        elif Error is botocore.exceptions.ResponseStreamingError:\n            assert s3_should_retry(Error(error=\"test\")) is True\n        elif Error is botocore.exceptions.ProxyConnectionError:\n            assert s3_should_retry(Error(proxy_url=\"test\")) is True\n        elif Error is botocore.exceptions.ConnectionClosedError:\n            assert s3_should_retry(Error(endpoint_url=\"test\")) is True\n        elif Error is botocore.exceptions.SSLError:\n            assert s3_should_retry(Error(endpoint_url=\"test\", error=\"test\")) is True\n        elif Error is urllib3.exceptions.HeaderParsingError:\n            assert s3_should_retry(Error(\"\", \"\")) is True\n        else:\n            assert s3_should_retry(Error()) is True\n\n    error_response = {\"Error\": {\"Code\": \"500\"}}\n    client_error = ClientError(error_response, operation_name=\"test\")\n    assert s3_should_retry(client_error) is True\n\n    error = Exception()\n    assert s3_should_retry(error) is False\n\n\ndef test_s3_endpoint_url(mocker):\n    class FakeMeta:\n        endpoint_url = \"test\"\n\n    class Fake:\n        def __init__(self) -> None:\n            self.meta = FakeMeta()\n            pass\n\n    def fake_get_endpoint_url(profile_name=None) -> str:\n        if profile_name:\n            return profile_name\n        return None\n\n    mocker.patch(\"megfile.s3.get_endpoint_url\", side_effect=fake_get_endpoint_url)\n    mocker.patch(\"megfile.s3.get_s3_client\", return_value=Fake())\n    assert s3_endpoint_url() == \"test\"\n    assert s3_endpoint_url(\"s3+test1://\") == \"test1\"\n    assert s3_endpoint_url(\"s3+test2://\") == \"test2\"\n\n\ndef test_translate_hdfs_error():\n    from megfile.hdfs_path import HdfsPath\n    from megfile.lib.hdfs_tools import hdfs_api\n\n    assert isinstance(\n        translate_hdfs_error(\n            hdfs_api.HdfsError(\n                message=\"Path is not a file\",\n            ),\n            hdfs_path=HdfsPath(\"hdfs://A/B/C\"),\n        ),\n        IsADirectoryError,\n    )\n\n    assert isinstance(\n        translate_hdfs_error(\n            hdfs_api.HdfsError(\n                message=\"Path is not a directory\",\n            ),\n            hdfs_path=HdfsPath(\"hdfs://A/B/C\"),\n        ),\n        NotADirectoryError,\n    )\n\n\ndef test_patch_method(caplog):\n    with caplog.at_level(logging.INFO, logger=\"megfile\"):\n        times = 0\n\n        def test():\n            nonlocal times\n            if times >= 2:\n                return\n\n            times += 1\n            raise ValueError(\"test\")\n\n        patched_test = patch_method(\n            test,\n            max_retries=2,\n            should_retry=lambda e: True,\n        )\n\n        with pytest.raises(ValueError):\n            patched_test()\n\n        times = 1\n        patched_test()\n        assert \"Error already fixed by retry\" in caplog.text\n\n\ndef test_pickle_error():\n    e = S3UnknownError(Exception(), \"\")\n    d = pickle.dumps(e)\n    pickle.loads(d)\n"
