[meta]
task = "update"
scenario = "update_test"

[lang_info]
lang = "Python"
python_version = "3.13"
python_cfg_file = "pyproject.toml"

[repo_info]
repository = "tqec/tqec"
sha = "3c0db694339614f537772a7bf6a183c8ffcb78a7"

[run_info]
docker_image = "python:3.13"
volumes_to_mount = [ "{proj_path}:/app", "{host}/.m2:/.m2", "{host}/.cache/pip:/.pip_cache", "{host}/.cache/go-build:/.go_cache", "{proj_path}/_HOME_/go:/go",]
docker_wrap = "sudo docker run --rm -w /app -e PATH=_HOME_/.local/bin:$PATH -e PYTHONUSERBASE=_HOME_/.local/ -v {proj_path}:/app -v {host}/.m2:/.m2 -v {host}/.cache/pip:/.pip_cache -v {host}/.cache/go-build:/.go_cache -v {proj_path}/_HOME_/go:/go {img} sh -c '{cmd}'"
env = [ "PATH=_HOME_/.local/bin:$PATH", "PYTHONUSERBASE=_HOME_/.local/",]
prebuild_command = "pip install -r requirements.txt && pip install -r requirements-dev.txt && (pip install .[all,test] && pip install git+https://github.com/Klema17/mutpy.git && pip install coverage pytest pytest_cov covdefaults Cython mock ddt pytest_mock testfixtures)"
test_run_command = "coverage run --include=src/tqec/compile/detectors/database.py -m pytest -q --junit-xml=test_output.xml src/tqec/compile/detectors/database_test.py && coverage xml -o coverage.xml --fail-under=0"
mutation_run_command = "mut.py --target src.tqec.compile.detectors.database --unit-test src.tqec.compile.detectors.database_test --runner pytest --report mutation_report.yaml"
mutation_run_command_fallback = "mut.py --target src/tqec/compile/detectors/database.py --unit-test src/tqec/compile/detectors/database_test.py --runner pytest --report mutation_report.yaml"
coverage_report_path = "coverage.xml"
coverage_report_type = "cobertura"
mutation_report_path = "mutation_report.yaml"
mutation_report_type = "mutpy"

[coverage]
coverage = 43.0
original_coverage = 72.0
mutation_kill_rate = nan
original_mutation_kill_rate = 97.0
covered_lines = [ 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 22, 23, 24, 25, 26, 27, 29, 32, 33, 67, 68, 70, 78, 79, 82, 83, 108, 109, 140, 143, 146, 169, 190, 191, 216, 217, 218, 239, 240, 245, 246, 250, 251, 256, 257, 259, 263, 268, 301, 331, 356, 380, 384, 388, 410, 413, 443, 444, 464, 483, 484,]
missed_lines = [ 71, 72, 80, 103, 133, 134, 135, 136, 137, 138, 141, 144, 156, 162, 163, 164, 165, 166, 167, 183, 209, 210, 213, 219, 220, 221, 222, 223, 224, 228, 229, 231, 232, 237, 241, 242, 243, 247, 248, 252, 253, 295, 296, 297, 298, 299, 326, 327, 328, 329, 351, 352, 353, 354, 377, 378, 382, 386, 401, 402, 403, 404, 405, 406, 407, 408, 411, 422, 423, 424, 425, 426, 427, 428, 430, 431, 455, 456, 462, 473, 474, 475, 476, 481, 495, 496, 500, 501, 506,]

[input_info]
test_file_path = "src/tqec/compile/detectors/database_test.py"
focal_file_path = "src/tqec/compile/detectors/database.py"
test_file_url = "https://github.com/tqec/tqec/blob/3c0db694339614f537772a7bf6a183c8ffcb78a7/src/tqec/compile/detectors/database_test.py"
focal_file_url = "https://github.com/tqec/tqec/blob/3c0db694339614f537772a7bf6a183c8ffcb78a7/src/tqec/compile/detectors/database.py"
first_commit_date = "2024-10-12"
last_commit_date = "2025-08-12"
test_file_content = "from collections.abc import Iterable\nfrom typing import cast\n\nimport numpy\nimport pytest\n\nfrom tqec.circuit.measurement import Measurement\nfrom tqec.circuit.qubit import GridQubit\nfrom tqec.compile.detectors.database import (\n    DetectorDatabase,\n    _DetectorDatabaseKey,  # pyright: ignore[reportPrivateUsage]\n)\nfrom tqec.compile.detectors.detector import Detector\nfrom tqec.compile.specs.library.generators.fixed_bulk import (\n    FixedBulkConventionGenerator,\n)\nfrom tqec.plaquette.compilation.base import IdentityPlaquetteCompiler\nfrom tqec.plaquette.plaquette import Plaquettes\nfrom tqec.plaquette.rpng.translators.default import DefaultRPNGTranslator\nfrom tqec.templates.qubit import QubitTemplate\nfrom tqec.templates.subtemplates import (\n    SubTemplateType,\n    get_spatially_distinct_subtemplates,\n)\nfrom tqec.utils.coordinates import StimCoordinates\nfrom tqec.utils.enums import Basis, Orientation\nfrom tqec.utils.exceptions import TQECException\n\nGENERATOR = FixedBulkConventionGenerator(DefaultRPNGTranslator(), IdentityPlaquetteCompiler)\n# Pre-computing Plaquettes and SubTemplateType instances to be able to re-use them\n# in tests.\n# WARNING: the order in which values of the two constants below are defined is\n#          important. If you change these lists, you will likely have to also\n#          change a few pre-computed values in tests that check that the computed\n#          hashes are reliable across OS, Python version, interpreter, ...\nPLAQUETTE_COLLECTIONS: list[Plaquettes] = [\n    GENERATOR.get_memory_qubit_plaquettes(Orientation.HORIZONTAL),\n    GENERATOR.get_memory_qubit_plaquettes(reset=Basis.Z),\n    GENERATOR.get_memory_qubit_plaquettes(reset=Basis.X),\n    GENERATOR.get_memory_qubit_plaquettes(measurement=Basis.Z),\n    GENERATOR.get_memory_qubit_plaquettes(Orientation.VERTICAL),\n]\n# Note: sorting is important here to guarantee the order in which subtemplates\n#       are in the SUBTEMPLATES list. See comment above PLAQUETTE_COLLECTIONS\n#       for more information.\nSUBTEMPLATES: list[SubTemplateType] = list(\n    cast(\n        Iterable[SubTemplateType],\n        numpy.sort(\n            list(\n                get_spatially_distinct_subtemplates(\n                    QubitTemplate().instantiate(k=10), manhattan_radius=2\n                ).subtemplates.values()\n            ),\n        ),\n    )\n)\n\nDETECTORS: list[frozenset[Detector]] = [\n    frozenset(\n        [\n            Detector(frozenset([Measurement(GridQubit(0, 0), -1)]), StimCoordinates(0, 0)),\n            Detector(\n                frozenset([Measurement(GridQubit(0, 0), -1), Measurement(GridQubit(0, 0), -2)]),\n                StimCoordinates(0, 0, 1),\n            ),\n            Detector(\n                frozenset(\n                    [\n                        Measurement(GridQubit(0, 0), -1),\n                        Measurement(GridQubit(-1, -1), -1),\n                        Measurement(GridQubit(-1, 1), -1),\n                        Measurement(GridQubit(1, -1), -1),\n                        Measurement(GridQubit(1, 1), -1),\n                    ]\n                ),\n                StimCoordinates(0, 0, 2),\n            ),\n        ]\n    ),\n    frozenset(\n        [\n            Detector(frozenset([Measurement(GridQubit(0, 0), -1)]), StimCoordinates(0, 0)),\n            Detector(\n                frozenset([Measurement(GridQubit(0, 0), -1), Measurement(GridQubit(0, 0), -2)]),\n                StimCoordinates(0, 0, 1),\n            ),\n        ]\n    ),\n]\n\n\ndef test_detector_database_key_creation() -> None:\n    _DetectorDatabaseKey((SUBTEMPLATES[0],), (PLAQUETTE_COLLECTIONS[0],))\n    _DetectorDatabaseKey(SUBTEMPLATES[1:5], PLAQUETTE_COLLECTIONS[1:5])\n    with pytest.raises(\n        TQECException,\n        match=\"^DetectorDatabaseKey can only store an equal number of \"\n        \"subtemplates and plaquettes. Got 4 subtemplates and 3 plaquettes.$\",\n    ):\n        _DetectorDatabaseKey(SUBTEMPLATES[1:5], PLAQUETTE_COLLECTIONS[1:4])\n\n\ndef test_detector_database_key_num_timeslices() -> None:\n    for i in range(min(len(PLAQUETTE_COLLECTIONS), len(SUBTEMPLATES))):\n        assert _DetectorDatabaseKey(SUBTEMPLATES[:i], PLAQUETTE_COLLECTIONS[:i]).num_timeslices == i\n\n\ndef test_detector_database_key_hash() -> None:\n    dbkey = _DetectorDatabaseKey(SUBTEMPLATES[1:5], PLAQUETTE_COLLECTIONS[1:5])\n    assert hash(dbkey) == hash(dbkey)\n    # This is a value that has been pre-computed locally. It is hard-coded here\n    # to check that the hash of a dbkey is reliable and does not change depending\n    # on the Python interpreter, Python version, host OS, process ID, ...\n    assert hash(dbkey) == 1068059953232381272\n\n    dbkey = _DetectorDatabaseKey(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1])\n    assert hash(dbkey) == hash(dbkey)\n    # This is a value that has been pre-computed locally. It is hard-coded here\n    # to check that the hash of a dbkey is reliable and does not change depending\n    # on the Python interpreter, Python version, host OS, process ID, ...\n    assert hash(dbkey) == 1986764458427930321\n\n\ndef test_detector_database_creation() -> None:\n    DetectorDatabase()\n\n\ndef test_detector_database_mutation() -> None:\n    db = DetectorDatabase()\n    db.add_situation(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1], DETECTORS[0])\n    db.add_situation(SUBTEMPLATES[:2], PLAQUETTE_COLLECTIONS[:2], DETECTORS[1])\n    with pytest.raises(\n        TQECException,\n        match=\"^DetectorDatabaseKey can only store an equal number of \"\n        \"subtemplates and plaquettes. Got 1 subtemplates and 2 plaquettes.$\",\n    ):\n        db.add_situation(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:2], DETECTORS[1])\n\n    detectors = db.get_detectors(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1])\n    assert detectors is not None\n    assert detectors == DETECTORS[0]\n\n    # Override\n    db.add_situation(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1], DETECTORS[1])\n    detectors2 = db.get_detectors(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1])\n    assert detectors2 is not None\n    assert detectors2 == DETECTORS[1]\n\n    # Removing\n    db.remove_situation(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1])\n    detectors3 = db.get_detectors(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1])\n    assert detectors3 is None\n\n\ndef test_detector_database_freeze() -> None:\n    db = DetectorDatabase()\n    db.add_situation(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1], DETECTORS[0])\n    db.add_situation(SUBTEMPLATES[:2], PLAQUETTE_COLLECTIONS[:2], DETECTORS[1])\n\n    db.freeze()\n    with pytest.raises(TQECException, match=\"^Cannot remove a situation to a frozen database.$\"):\n        db.remove_situation(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1])\n    with pytest.raises(TQECException, match=\"^Cannot add a situation to a frozen database.$\"):\n        db.add_situation(SUBTEMPLATES[:4], PLAQUETTE_COLLECTIONS[:4], DETECTORS[1])\n\n    detectors = db.get_detectors(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1])\n    assert detectors is not None\n    assert detectors == DETECTORS[0]\n\n    db.unfreeze()\n    db.remove_situation(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1])\n    db.add_situation(SUBTEMPLATES[:4], PLAQUETTE_COLLECTIONS[:4], DETECTORS[1])\n    detectors2 = db.get_detectors(SUBTEMPLATES[:4], PLAQUETTE_COLLECTIONS[:4])\n    assert detectors2 is not None\n    assert detectors2 == DETECTORS[1]\n\n\ndef test_detector_database_translation_invariance() -> None:\n    db = DetectorDatabase()\n    db.add_situation(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1], DETECTORS[0])\n\n    offset = 36\n    translated_subtemplate = SUBTEMPLATES[0] + offset\n    translated_plaquettes = PLAQUETTE_COLLECTIONS[0].map_indices(lambda i: i + offset)\n    detectors = db.get_detectors((translated_subtemplate,), (translated_plaquettes,))\n    assert detectors is not None\n    assert detectors == DETECTORS[0]\n\n\ndef test_detector_database_dict() -> None:\n    db = DetectorDatabase()\n    db.add_situation(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1], DETECTORS[0])\n    db.add_situation(SUBTEMPLATES[:2], PLAQUETTE_COLLECTIONS[:2], DETECTORS[1])\n\n    # Check that the database can be converted to a dict and back\n    db_dict = db.to_dict()\n    new_db = DetectorDatabase.from_dict(db_dict)\n\n    # Check that the new database has the same situations as the original\n    detectors0 = new_db.get_detectors(SUBTEMPLATES[:1], PLAQUETTE_COLLECTIONS[:1])\n    assert detectors0 is not None\n    assert detectors0 == DETECTORS[0]\n    detectors1 = new_db.get_detectors(SUBTEMPLATES[:2], PLAQUETTE_COLLECTIONS[:2])\n    assert detectors1 is not None\n    assert detectors1 == DETECTORS[1]"
